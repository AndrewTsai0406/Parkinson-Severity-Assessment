{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 - Introduction\n\nWelcome to the [AMP - Parkinson's Disease Progression Prediction](https://www.kaggle.com/competitions/amp-parkinsons-disease-progression-prediction/overview) challenge. The purpose of this notebook is to take a deep dive into the dataset provided for the competition and understand some of the general trends and features that occur in the supplied source datafiles. This particular notebook is broken into two parts:\n\n* Exploratory Data Analysis (EDA) - a walkthrough of various trends and data, along with a summary of key observations from each.\n* Empirical Modeling - empirical testing of observations through the use of simple models.\n\nIn this competition, we are looking at the Unified Parkinson's Disease Rating Scale (UPDRS) that was revised by the Movement Disorder Society (MDS) in 2008. This new scale - the MDS-UPDRS (which we will refer to within this EDA as simply the UPDRS) - consists of 4 separate parts. Each part consists of a questionnaire that rates signs or symptoms of Parkinson's Disease (PD). According to Holden et al (2018), the individual parts consist of:\n\n* Part I - Non-Motor Aspects of Experiences of Daily Living\n* Part II - Motor Aspects of Experiences of Daily Living\n* Part III - Motor Examination\n* Part IV - Motor Complications\n\nQuestions within each part are scored on a 5 point scale ranging in values from 0 (normal) to 4 (most severe impairment). The maximum score that a patient may be assigned is 272 points. The challenge in this competition is to predict the UPDRS scores for parts 1 - 4 for each month that the patient had a visit and evaluation with a physician. The primary features that the competition provides to make the predictions are mass spectrometry readings of cerebrospinal fluid (CSF) samples collected from patients at different months. The CSF samples contain protein information, as well as protein sub-component information in the form of peptide chains. \n\nThis competition is a notebooks only competition, which makes use of a specific [Kaggle timeseries API](https://www.kaggle.com/code/sohier/basic-api-demo) to fetch data and make predictions on competition data. The API presents testing data in chronological order, which prevents users from peeking forward in time to see protein and peptide information for future visits. The metric used for this competition is [Symmetric Mean Absolute Percentage Error](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error) (SMAPE).","metadata":{}},{"cell_type":"markdown","source":"# 1.1 - Initial Impressions\n\nLet's look at the memory and disk footprints first, as this can sometimes be a limiting factor on what we can do. As a sidenote - we won't look a the example test data because this is a code competition. Test data will be supplied using the [Kaggle timeseries API](https://www.kaggle.com/code/sohier/basic-api-demo), and will be made available to the kernel at the time of submission.\n\n| Dataset                      | Size on Disk | Size in Memory |\n| ---------------------------- | ------------ | -------------- |\n| `train_clinical_data`        | 73 KB        | 159.73 KB      |\n| `train_peptides`             | 49 MB        |  44.94 MB      |\n| `train_proteins`             | 7.5 KB       |   8.88 MB      |\n| `supplemental_clinical_data` | 75 KB        | 135.80 KB      |\n\nAs we can see, memory pressure isn't too bad, nor is disk space storage. This means that we won't likely have too many problems with various machine learning features. \n\nLet's take a deeper dive into the datasets next. For this particular challenge, each dataset represents a series of observations associated with a particular patient. The observations contain information relating to mass spectrometry readings of cerebrospinal fluid (CSF). Some of the data we have does not have any CSF readings associated with it. The CSF readings contain both the expression frequency of proteins within the CSF, and the associated peptide frequencies (peptides are subunits of proteins). Let's take a quick glance at the columns to see what we are dealing with.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrain_clinical_data = pd.read_csv(\"../input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\ntrain_peptides = pd.read_csv(\"../input/amp-parkinsons-disease-progression-prediction/train_peptides.csv\")\ntrain_protiens = pd.read_csv(\"../input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\")\nsupplemental_clinical_data = pd.read_csv(\"../input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_clinical_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\": Found {:,d} unique patient_id values\".format(train_clinical_data[\"patient_id\"].nunique()))\nprint(\": Found {:,d} unique visit_month values\".format(train_clinical_data[\"visit_month\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_peptides","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\": Found {:,d} unique patient_id values\".format(train_peptides[\"patient_id\"].nunique()))\nprint(\": Found {:,d} unique UniProt values\".format(train_peptides[\"UniProt\"].nunique()))\nprint(\": Found {:,d} unique Peptide values\".format(train_peptides[\"Peptide\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_protiens","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\": Found {:,d} unique patient_id values\".format(train_protiens[\"patient_id\"].nunique()))\nprint(\": Found {:,d} unique visit_month values\".format(train_protiens[\"visit_month\"].nunique()))\nprint(\": Found {:,d} unique UniProt values\".format(train_protiens[\"UniProt\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"supplemental_clinical_data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\": Found {:,d} unique patient_id values\".format(supplemental_clinical_data[\"patient_id\"].nunique()))\nprint(\": Found {:,d} unique visit_month values\".format(supplemental_clinical_data[\"visit_month\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined = pd.concat([train_clinical_data, supplemental_clinical_data]).reset_index(drop=True)\ncombined","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\": Found {:,d} unique patient_id values\".format(combined[\"patient_id\"].nunique()))\nprint(\": Found {:,d} unique visit_month values\".format(combined[\"visit_month\"].nunique()))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are quite a few observations to unpack here. Let's summarize them.\n\n### Key Observations About Initial Impressions\n\n* Size in terms of both disk usage and memory usage is small - this means that we likely won't be facing too much memory pressure.\n    * This is good news, since the Kaggle VMs are limited to 16 GB of RAM.\n* For `train_clinical_data`:\n    * This dataset represents the scores that a patient had on a particular month for part N of the [Unified Parkinson's Disease Rating Scale](https://www.movementdisorders.org/MDS/MDS-Rating-Scales/MDS-Unified-Parkinsons-Disease-Rating-Scale-MDS-UPDRS.htm)\n    * Contains a mixture of categorical (`upd23b_clinical_state_on_medication`) and continuous (`visit_month`, `updrs_[1-4]`) features.\n    * Contains 2,615 rows of data, and spans:\n        * 248 unique `patient_id` values\n* For `train_peptides`:\n    * This dataset represents the peptide frequencies within the CSF seen for a particular patient on a particular month.\n    * This dataset joins to the `train_clinical_data` dataset based on `visit_id`.\n    * Contains a mixture of categorical (`UniProt`, `Peptide`) and continuous (`Peptide Abundance`) features.\n    * Contains 981,834 rows of data, and spans:\n        * 248 unique `patient_id` values\n        * 227 unique `UnitProt` values\n        * 968 unique `Peptide` values\n* For `train_proteins`:\n    * This dataset represents the protein expression frequencies within the CSF seen for a particular patient on a particular month.\n    * This dataset joins to the `train_clinical_data` dataset based on `visit_id`.\n    * Contains a mixture of categorical (`UniProt`) and continuous (`NPX`) features.\n    * Contains 232,741 rows of data, and spans:\n        * 248 unique `patient_id` values\n        * 227 unique `UniProt` values\n* For `supplemental_clinical_data`:\n    * This dataset represents supplemental information that does not have any protein or peptide measurements from CSF, and represents the scores that a patient had on a particular month for part N of the [Unified Parkinson's Disease Rating Scale](https://www.movementdisorders.org/MDS/MDS-Rating-Scales/MDS-Unified-Parkinsons-Disease-Rating-Scale-MDS-UPDRS.htm)\n    * Contains a mixture of categorical (`upd23b_clinical_state_on_medication`) and continuous (`visit_month`, `updrs_[1-4]`) features.\n    * Contains 2,223 rows of data, and spans:\n        * 771 unique `patient_id` values\n* In total, there are:\n    * 4,838 unique visits\n    * 1,019 unique patients\n    * 18 unique month values","metadata":{}},{"cell_type":"markdown","source":"# 1.2 - Null Values\n\nLet's explore the issue of missing values in the dataset to see if there are systemic problems with data representation.","metadata":{}},{"cell_type":"code","source":"train_clinical_data[\"null_count\"] = train_clinical_data.isnull().sum(axis=1)\ncounts_train_clinical_data = train_clinical_data.groupby(\"null_count\")[\"visit_id\"].count().to_dict()\nnull_train_clinical_data = {\"{} Null Value(s)\".format(k) : v for k, v in counts_train_clinical_data.items()}\n\ntrain_peptides[\"null_count\"] = train_peptides.isnull().sum(axis=1)\ncounts_train_peptides = train_peptides.groupby(\"null_count\")[\"visit_id\"].count().to_dict()\nnull_train_peptides = {\"{} Null Value(s)\".format(k) : v for k, v in counts_train_peptides.items()}\n\ntrain_protiens[\"null_count\"] = train_protiens.isnull().sum(axis=1)\ncounts_train_protiens = train_protiens.groupby(\"null_count\")[\"visit_id\"].count().to_dict()\nnull_train_protiens = {\"{} Null Value(s)\".format(k) : v for k, v in counts_train_protiens.items()}\n\nsupplemental_clinical_data[\"null_count\"] = supplemental_clinical_data.isnull().sum(axis=1)\ncounts_supplemental_clinical_data = supplemental_clinical_data.groupby(\"null_count\")[\"visit_id\"].count().to_dict()\nnull_supplemental_clinical_data = {\"{} Null Value(s)\".format(k) : v for k, v in counts_supplemental_clinical_data.items()}\n\nfig, axs = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))\n\naxs = axs.flatten()\n\n_ = axs[0].pie(\n    x=list(null_train_clinical_data.values()), \n    autopct=lambda x: \"{:,.0f} = {:.2f}%\".format(x * sum(null_train_clinical_data.values())/100, x),\n    explode=[0.05] * len(null_train_clinical_data.keys()), \n    labels=null_train_clinical_data.keys(), \n    colors=sns.color_palette(\"Set2\")[0:len(null_train_clinical_data.keys())],\n)\n_ = axs[0].set_title(\"Null Values Per Row in Clinical Data\", fontsize=15)\n\n_ = axs[3].pie(\n    x=list(null_train_peptides.values()), \n    autopct=lambda x: \"{:,.0f} = {:.2f}%\".format(x * sum(null_train_peptides.values())/100, x),\n    explode=[0.05] * len(null_train_peptides.keys()), \n    labels=null_train_peptides.keys(), \n    colors=sns.color_palette(\"Set2\")[0:len(null_train_peptides.keys())],\n)\n_ = axs[3].set_title(\"Null Values Per Row in Peptide Data\", fontsize=15)\n\n_ = axs[2].pie(\n    x=list(null_train_protiens.values()), \n    autopct=lambda x: \"{:,.0f} = {:.2f}%\".format(x * sum(null_train_protiens.values())/100, x),\n    explode=[0.05] * len(null_train_protiens.keys()), \n    labels=null_train_protiens.keys(), \n    colors=sns.color_palette(\"Set2\")[0:len(null_train_protiens.keys())],\n)\n_ = axs[2].set_title(\"Null Values Per Row in Protein Data\", fontsize=15)\n\n_ = axs[1].pie(\n    x=list(null_supplemental_clinical_data.values()), \n    autopct=lambda x: \"{:,.0f} = {:.2f}%\".format(x * sum(null_supplemental_clinical_data.values())/100, x),\n    explode=[0.05] * len(null_supplemental_clinical_data.keys()), \n    labels=null_supplemental_clinical_data.keys(), \n    colors=sns.color_palette(\"Set2\")[0:len(null_supplemental_clinical_data.keys())],\n)\n_ = axs[1].set_title(\"Null Values Per Row in Supplemental Clinical Data\", fontsize=15)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The good news is that we don't have any null values when it comes to CSF observations with the peptide and protein data. We do however see null values when it comes to the clinical data. Let's see what we are missing and why. We'll start with the clinical data.","metadata":{}},{"cell_type":"code","source":"null_count_labels = [train_clinical_data[(train_clinical_data[\"null_count\"] == x)].isnull().sum().index[:-1] for x in range(1, 6)]\nnull_count_values = [train_clinical_data[(train_clinical_data[\"null_count\"] == x)].isnull().sum().values[:-1] for x in range(1, 6)]\n\nfig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\nfig.suptitle(\"Null Values for Clinical Data\", fontsize=20)\n\naxs = axs.flatten()\n\nfor x in range(0, 4):\n    ax = axs[x]\n    labels = null_count_labels[x]\n    _ = sns.barplot(x=labels, y=null_count_values[x], ax=ax)\n    _ = ax.set_title(\"Number of Rows With {} Null(s)\".format(x + 1), fontsize=15)\n    _ = ax.set_ylabel(\"# of Nulls\" if x == 0 else \"\")\n    _ = ax.set_xlabel(\"\")\n    _ = ax.set_xticks([z for z in range(len(labels))], labels, rotation=90)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(x=p.get_x()+(p.get_width()/2), y=height, s=\"{:d}\".format(int(height)), ha=\"center\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are starting to see some interesting trends. Let's break this down by null counts.\n\n### Rows with 1 Null Value\n\nWhen there is a single null value in the row, it usually corresponds to the feature `upd23b_clinical_state_on_medication`. Valid responses are one of `On` or `Off`. Null values within the field are of interest, as it is uncertain whether they indicate that the patient was `Off` of medication, or if the assessment failed to capture the medication status of the patient. In the other two instances of null value counts, they occur 7 times in `updrs_3` and 21 times in `updrs_4`. According to Goetz et al (2008), part 3 of the UPDRS assessment concerns motor assessment, and has a minimum score of 0. Part 4 of the UPDRS assessment concerns motor complications, and again has a minimum score of 0. Null values in either of those columns suggest that the assessment was not performed. This is important, as a score of 0 indicates that the patient was assessed and was deemed to have normal responses. \n\n### Rows with 2 Null Values\n\nWhen there are two null values in the row, they usually correspond to `updrs_4` and `upd23b_clinical_state_on_medication`. As mentioned previously, valid responses are `On` or `Off`, thus a null value here is of interest as we cannot be certain whether the assessment failed to capture medication status. The majority of the other null value fields occur with `updrs_4`, which concerns motor complications. Other null values occur infrequently in the `updrs_3`, and `updrs_2` fields. Again, UPDRS part 3 concerns motor assessment, and null values here cannot assumed to be 0 scores, given that 0 indicates normal function. With UPDRS part 2, the assessment concerns motor experiences of daily living, and again, null values here may indicate that the assessment was not performed. \n\n### Rows with 3 Null Values\n\nThere are 10 instances where rows contain 3 null values. In each instance, the row is missing information from `updrs_3`, `updrs_4`, and `upd23b_clinical_state_on_medication`. Again missing values cannot be assumed to be 0.\n\n### Rows with 4 Null Values\n\nOnly a single instance of a row with 4 null values occurs. It appears that only the UPDRS part 3 assessment was performed at the visit. Again, null values cannot be interpreted as being 0, given that 0 based scores indicate a normal response. ","metadata":{}},{"cell_type":"markdown","source":"We need to also look at the supplemental information for null values.","metadata":{}},{"cell_type":"code","source":"null_count_labels = [supplemental_clinical_data[(supplemental_clinical_data[\"null_count\"] == x)].isnull().sum().index[:-1] for x in range(1, 6)]\nnull_count_values = [supplemental_clinical_data[(supplemental_clinical_data[\"null_count\"] == x)].isnull().sum().values[:-1] for x in range(1, 6)]\n\nfig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 5))\nfig.suptitle(\"Null Values for Supplemental Data\", fontsize=20)\n\naxs = axs.flatten()\n\nfor x in range(0, 4):\n    ax = axs[x]\n    labels = null_count_labels[x]\n    _ = sns.barplot(x=labels, y=null_count_values[x], ax=ax)\n    _ = ax.set_title(\"Number of Rows With {} Null(s)\".format(x + 1), fontsize=15)\n    _ = ax.set_ylabel(\"# of Nulls\" if x == 0 else \"\")\n    _ = ax.set_xlabel(\"Feature\")\n    _ = ax.set_xticks([z for z in range(len(labels))], labels, rotation=90)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(x=p.get_x()+(p.get_width()/2), y=height, s=\"{:d}\".format(int(height)), ha=\"center\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, similar patterns emerge. When there is a single null value in a row, it either appears in `updrs_4` and `upd23b_clinical_state_on_medication`. The same trend continues when there are two null values. When there are three null values, the trend differs slightly from the clinical data. In this case, the supplemental data is more likely to be missing `updrs_1` and `updrs_2` when compared to the clinical data. Finally, when there are four missing values, we see the same missing values in `updrs_1`, `updrs_2`, `updrs_4` and `upd23b_clinical_state_on_medication`. There is a significantly higher number of 4 null value rows in the supplemental data than in the clinical data.\n\n### Key Observations About Null Values\n\n* No null values are missing from peptide and protein data.\n* Null values occur in the clinical data and supplemental data. General trends are:\n    * Single null values occur most frequently in the `updrs_4` and `upd23b_clinical_state_on_medication` features.\n    * Two null values occur most frequently in the `updrs_4` and `upd23b_clinical_state_on_medication` features.\n    * Three null values occur most frequently in the:\n        * `updrs_3`, `updrs_4`, and `upd23b_clinical_state_on_medication` features for the clinical data.\n        * `updrs_1`, `updrs_2`, and `upd23b_clinical_state_on_medication` features for the supplemental data.\n    * Four null values occur most frequently in the `updrs_1`, `updrs_2`, `updrs_4`, and `upd23b_clinical_state_on_medication` features.\n* The supplemental data has many more examples of rows with four null values when compared to the clinical data.\n* Care must be taken when dealing with null values:\n    * It is not apparent whether the null values should be used to indicate a missed assessment, or whether they can be set to another value.\n        * For UPDRS assessments, it may be erroneous to set the value to 0 as that would indicate a \"normal\" result.\n        * For the `upd23b_clinical_state_on_medication` feature, the only valid settings are `On` or `Off`, thus the impact of null is undefined.","metadata":{}},{"cell_type":"markdown","source":"# 1.3 - Duplicated Rows\n\nWe should next check to see if we have any duplicated values in our various datasets. Duplicates may impact our learning methods, resulting in prediction bias toward the duplicate information. ","metadata":{}},{"cell_type":"code","source":"titles = [\"Peptide Data\", \"Protein Data\", \"Clinical Data\", \"Supplemental Data\"]\nvalue_counts = []\nduplicates = train_peptides.pivot_table(index=[\n    'UniProt', 'Peptide', 'PeptideAbundance',\n], aggfunc=\"size\")\nunique, counts = np.unique(duplicates, return_counts=True)\nvalue_counts.append(dict(zip(unique, counts)))\n\nduplicates = train_protiens.pivot_table(index=[\n    'UniProt', 'NPX',\n], aggfunc=\"size\")\nunique, counts = np.unique(duplicates, return_counts=True)\nvalue_counts.append(dict(zip(unique, counts)))\n\nduplicates = train_clinical_data.pivot_table(index=[\n    'visit_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication'\n], aggfunc=\"size\")\nunique, counts = np.unique(duplicates, return_counts=True)\nvalue_counts.append(dict(zip(unique, counts)))\n\nduplicates = supplemental_clinical_data.pivot_table(index=[\n    'visit_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication'\n], aggfunc=\"size\")\nunique, counts = np.unique(duplicates, return_counts=True)\nvalue_counts.append(dict(zip(unique, counts)))\n\nfig, axs = plt.subplots(nrows=1, ncols=4, figsize=(20, 4))\n\naxs = axs.flatten()\n\nfor x in range(4):\n    ax = axs[x]\n    _ = sns.barplot(x=list(value_counts[x].keys())[1:], y=list(value_counts[x].values())[1:], ax=ax)\n    _ = ax.set_title(\"Duplicate Counts in {}\".format(titles[x], fontsize=15))\n    _ = ax.set_ylabel(\"Count\")\n    _ = ax.set_xlabel(\"Number of Times Row is Duplicated\")\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(x=p.get_x()+(p.get_width()/2), y=height, s=\"{:d}\".format(int(height)), ha=\"center\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Key Observations About Duplicated Rows\n\n* In terms of raw duplicates:\n    * In the clinical data:\n        * There are 2 instances where the same row of data appears twice.\n        * Duplicates account for 0.15% of all clinical data.\n    * In the supplemental data:\n        * There are 7 instances where the same row of data appears twice.\n        * Duplicates account for 0.63% of all supplemental data.\n    * In the protein data:\n        * There are 400 instances where the same row of data appears twice.\n        * Duplicates account for 0.35% of all protein data.\n    * In the peptide data:\n        * There are 1,765 instances where the same row of data appears twice.\n        * There are 2 instances where the same row of data appears 3 times.\n        * Duplicates account for 0.36% of all peptide data.\n* Overall, with the clinical and supplemental data, duplicates are likely to have little or no impact.","metadata":{}},{"cell_type":"markdown","source":"# 1.4 - Statistical Breakdown\n\nLet's take a closer look at some of the statistical properties of the continuous features. \n\n## 1.4.1 - Clinical vs Supplemental Data\n\nTo begin, let's compare the clinical data to the supplemental data to see what kind of differences we have.\n\n### Clinical Data","metadata":{}},{"cell_type":"code","source":"features = [\n    'visit_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4',\n]\n\ntrain_clinical_data[features].describe().T.style.bar(subset=['mean'], color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Supplemental Data","metadata":{}},{"cell_type":"code","source":"features = [\n    'visit_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4',\n]\n\nsupplemental_clinical_data[features].describe().T.style.bar(subset=['mean'], color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Supplemental data appears to have visits that occur mainly between 0 and 36 months, while clinical data shows visits occurring between 0 and 108 months. We can confirm this by looking at kernel density estimates for the months of the various visits.","metadata":{}},{"cell_type":"code","source":"train_clinical_data[\"origin\"] = \"Clincial Data\"\nsupplemental_clinical_data[\"origin\"] = \"Supplemental Data\"\n\ncombined = pd.concat([train_clinical_data, supplemental_clinical_data]).reset_index(drop=True)\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n\nsns.set_style('darkgrid')\n\n_ = sns.histplot(data=combined, x=\"visit_month\", hue=\"origin\", kde=True, ax=ax, element=\"step\")\n_ = ax.set_title(\"Visit Month by Data Source\", fontsize=15)\n_ = ax.set_ylabel(\"Count\")\n_ = ax.set_xlabel(\"Visit Month\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the supplemental data is focused around 0 month visits, and ends at 36 months, while the clinical data spans a much longer time-frame. We can also do a quick visual check to see if there are differences between the clinical and supplemental data when it comes to UPDRS scores. For the figures below, the trend lines are kernel density estimates, thus differences in raw counts are taken into consideration with the trend lines.","metadata":{}},{"cell_type":"code","source":"train_clinical_data[\"origin\"] = \"Clincial Data\"\nsupplemental_clinical_data[\"origin\"] = \"Supplemental Data\"\n\ncombined = pd.concat([train_clinical_data, supplemental_clinical_data]).reset_index(drop=True)\n\nfeatures = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\nlabels = [\"UPDRS Part 1\", \"UPDRS Part 2\", \"UPDRS Part 3\", \"UPDRS Part 4\"]\n\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(15, 25))\n\nsns.set_style('darkgrid')\n\naxs = axs.flatten()\n\nsns.set_style('darkgrid')\n\nfor x, feature in enumerate(features):\n    ax = axs[x]\n    _ = sns.histplot(data=combined, x=feature, hue=\"origin\", kde=True, ax=ax, element=\"step\")\n    _ = ax.set_title(\"{} Scores by Data Source\".format(labels[x]), fontsize=15)\n    _ = ax.set_ylabel(\"Count\")\n    _ = ax.set_xlabel(\"{} Score\".format(labels[x]))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a few interesting observations:\n\n* UPDRS Part 1 and 4 scores appear to be fairly similar in their distribution between the clinical and supplemental data sources.\n* UPDRS Part 2 and 3 scores have a much higher proportion of 0 based scores in the clinical data when compared to the supplemental data source.","metadata":{}},{"cell_type":"markdown","source":"As a final check, we can get a rough measure of the differences between the clinical data and supplemental data by performing an adversarial validation. The goal with adversarial validation is to see if a classifier can tell the two datasets apart. We'll use ROC AUC score to inform us of differences. If the two sets appear to be very similar, the classifier will not be able to tell them apart, and thus will have an ROC AUC score of 0.5. If they are easy to tell apart - and thus are very dissimilar - then the ROC AUC score will approach 1. ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\nfrom lightgbm import early_stopping, log_evaluation\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve\nfrom sklearn.preprocessing import LabelEncoder\n\ntrain_clinical_data[\"origin\"] = 0\nsupplemental_clinical_data[\"origin\"] = 1\n\ncombined = pd.concat([train_clinical_data, supplemental_clinical_data]).reset_index(drop=True)\n\nfeatures = [\n    'visit_month', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4', 'upd23b_clinical_state_on_medication',\n]\n\nle = LabelEncoder()\ncombined['upd23b_clinical_state_on_medication'] = le.fit_transform(combined['upd23b_clinical_state_on_medication'])\n    \nn_folds = 5\nskf = KFold(n_splits=n_folds, random_state=2023, shuffle=True)\ntrain_oof_preds = np.zeros((combined.shape[0],))\ntrain_oof_probas = np.zeros((combined.shape[0],))\n\nfor fold, (train_index, test_index) in enumerate(skf.split(combined, combined[\"origin\"])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(combined.iloc[train_index]), pd.DataFrame(combined.iloc[test_index])\n    y_train, y_valid = combined[\"origin\"].iloc[train_index], combined[\"origin\"].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = LGBMClassifier(\n        random_state=2023,\n        objective=\"binary\",\n        metric=\"auc\",\n        n_jobs=-1,\n        n_estimators=2000,\n        verbose=-1,  \n        max_depth=3,\n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        callbacks=[\n            early_stopping(50, verbose=False),\n            log_evaluation(2000),\n        ]\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    oof_probas = model.predict_proba(x_valid_features[features])[:,1]\n    train_oof_preds[test_index] = oof_preds\n    train_oof_probas[test_index] = oof_probas\n    print(\": AUC ROC = {}\".format(roc_auc_score(y_valid, oof_probas)))\n    \nauc_vanilla = roc_auc_score(combined[\"origin\"], train_oof_probas)\nfpr, tpr, _ = roc_curve(combined[\"origin\"], train_oof_probas)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": AUC ROC = {}\".format(auc_vanilla))\n\nconfusion = confusion_matrix(combined[\"origin\"], train_oof_preds)\n\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 8))\n\nlabels = [\"Clincial Data\", \"Supplemental Data\"]\n\n_ = sns.heatmap(confusion, annot=True, fmt=\",d\", ax=axs[0], xticklabels=labels, yticklabels=labels)\n_ = axs[0].set_title(\"Confusion Matrix (@ 0.5 Probability)\", fontsize=15)\n_ = axs[0].set_ylabel(\"Actual Class\")\n_ = axs[0].set_xlabel(\"Predicted Class\")\n\n_ = sns.lineplot(x=[0, 1], y=[0, 1], linestyle=\"--\", label=\"Indistinguishable Datasets\", ax=axs[1])\n_ = sns.lineplot(x=fpr, y=tpr, ax=axs[1], label=\"Adversarial Validation Classifier\")\n_ = axs[1].set_title(\"ROC Curve\", fontsize=15)\n_ = axs[1].set_xlabel(\"False Positive Rate\")\n_ = axs[1].set_ylabel(\"True Positive Rate\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With an AUC ROC score of 0.939, we can see that the classifier can easily tell the two datasets apart. This suggests that they are very dissimilar in nature, as was indicated as part of the competition. Caution should be used when mixing these two datasets, as they are very different in nature.","metadata":{}},{"cell_type":"markdown","source":"## 1.4.2 - Protein Data\n\nLet's take a look at the values we have for protein data.","metadata":{}},{"cell_type":"code","source":"train_protiens[[\"NPX\"]].describe().T.style.bar(subset=['mean'], color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Protein expression frequency values appear to have a wide range of values. We'll use a quick kernel density estimate to get an idea of where frequencies are clustered. We'll use a logarithmic scale due to the large values and potential variability involved in the expression frequencies.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n\nsns.set_style('darkgrid')\n\n_ = sns.kdeplot(train_protiens[\"NPX\"], shade=True, color=\"r\", ax=ax, label=\"Normalized Protein Expression\", log_scale=True)\n_ = ax.set_title(\"Logarithmic Normalized Protein Expression (Kernel Density Estimate)\", fontsize=15)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, there is a lot of variability regarding the actual protein expression frequencies. We'll look more into the distribution of various proteins and their association to the UPDRS scores in section 2 below. For now, the key observation we have is that normalized protein expression is highly variable, as indicated by the min, max, and standard deviation of the feature.","metadata":{}},{"cell_type":"markdown","source":"## 1.4.3 - Peptide Data\n\nLet's take a look at what we have for the peptide data.","metadata":{}},{"cell_type":"code","source":"train_peptides[[\"PeptideAbundance\"]].describe().T.style.bar(subset=['mean'], color='#7BCC70')\\\n    .background_gradient(subset=['std'], cmap='Reds')\\\n    .background_gradient(subset=['50%'], cmap='coolwarm')","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, we see a wide variation in the abundance of peptides. The min, max, and standard deviation tell us that peptide abundances will likely vary greatly depending on the particular peptide we are looking at. Again, we can plot kernel density estimates to give us an idea of where the bulk of our values exist.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n\nsns.set_style('darkgrid')\n\n_ = sns.kdeplot(train_peptides[\"PeptideAbundance\"], shade=True, color=\"r\", ax=ax, label=\"Peptide Abundance\", log_scale=True)\n_ = ax.set_title(\"Logarithmic Peptide Abundance (Kernel Density Estimate)\", fontsize=15)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, we'll look at peptide data - specifically peptide sequences and how they relate to UPDRS scores - in section 2 below.","metadata":{}},{"cell_type":"markdown","source":"### Key Observations About Statistical Breakdown\n\n* The clinical data and supplementary data have very different month ranges:\n    * This was confirmed by looking at their statistical properties, histograms, and adversarial validation.\n* Protein expression data has a wide range of values, and thus will need to be further broken down into sub-groupings to be informative.\n* Peptide abundance frequencies has a wide range of values, and thus will need to be further broken down into sub-groupings to be informative.","metadata":{}},{"cell_type":"markdown","source":"# 2 - Feature Exploration\n\nIn this section, we will examine each of the features we have to work with in more detail.\n\n# 2.1 - Visit Month\n\nThe visit month has an impact across all of the different datasets, and subsequently, through many different features that we have. Let's take a look at them in turn.\n\n# 2.1.1 - Visit Month vs UPDRS \n\nFor each visit month, we have observations about the target features - UPDRS scores. According to Holden et al (2018), the findings in each part of the UPDRS were dependent on whether or not the patient was taking medication. We should sub-divide the UPDRS score observations into groups that were taking medication, and those that were not. For the purposes of this exploration, a null value found in clinical data regarding medication state will be considered to be `Off`.","metadata":{}},{"cell_type":"code","source":"train_clincial_data_copy = train_clinical_data.copy()\ntrain_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] = train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"].fillna(\"Off\")\n\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(15, 25))\n\nsns.set_style('darkgrid')\n\naxs = axs.flatten()\n\nfor x, feature in enumerate([\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]):\n    ax = axs[x]\n    data = train_clincial_data_copy[(train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] == \"Off\")]\n    _ = sns.boxplot(data=data, x=\"visit_month\", y=feature, ax=ax)\n    _ = sns.pointplot(data=data, x=\"visit_month\", y=feature, color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n    _ = ax.set_title(\"UPDRS Part {} Scores by Month while OFF Medication\".format(x+1), fontsize=15)\n    _ = ax.set_xlabel(\"Visit Month\")\n    _ = ax.set_ylabel(\"Score\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some general observations when OFF medication:\n    \n* There is a large amount of variance and outliers across each of the UPDRS parts and their respective visit months.\n* In general across UPDRS Parts 1 - 3, the trendline of score remains relatively flat.\n    * With UPDRS Part 4, we see a gradual increase in score.","metadata":{}},{"cell_type":"code","source":"train_clincial_data_copy = train_clinical_data.copy()\ntrain_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] = train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"].fillna(\"Off\")\n\nfig, axs = plt.subplots(nrows=4, ncols=1, figsize=(15, 25))\n\nsns.set_style('darkgrid')\n\naxs = axs.flatten()\n\nfor x, feature in enumerate([\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]):\n    ax = axs[x]\n    data = train_clincial_data_copy[(train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] == \"On\")]\n    _ = sns.boxplot(data=data, x=\"visit_month\", y=feature, ax=ax)\n    _ = sns.pointplot(data=data, x=\"visit_month\", y=feature, color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n    _ = ax.set_title(\"UPDRS Part {} Scores by Month while ON Medication\".format(x+1), fontsize=15)\n    _ = ax.set_xlabel(\"Visit Month\")\n    _ = ax.set_ylabel(\"Score\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some general observations when ON medication:\n    \n* There is a large amount of variance and outliers across each of the UPDRS parts and their respective visit months.\n* In general across UPDRS Parts 1, 2, and 4, the trendline of score remains relatively flat.\n    * With UPDRS Part 3, we see a gradual increase in score.\n\nAs mentioned by Holden et al (2018), the maximum score of the UPDRS is 272. In prior versions of the UPDRS, there was a linear progression of UPDRS score as time progressed. We should look at the sum total of the UPDRS scores to see if there is a score increase over time within this data.","metadata":{}},{"cell_type":"code","source":"train_clinical_data[\"updrs_sum\"] = train_clinical_data[\"updrs_1\"] + train_clinical_data[\"updrs_2\"] + train_clinical_data[\"updrs_3\"] + train_clinical_data[\"updrs_4\"]\ntrain_clincial_data_copy = train_clinical_data.copy()\ntrain_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] = train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"].fillna(\"Off\")\n\nfig, axs = plt.subplots(nrows=2, ncols=1, figsize=(15, 12.5))\n\naxs = axs.flatten()\n\nsns.set_style('darkgrid')\n\ndata = train_clincial_data_copy[(train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] == \"Off\")]\nax = axs[0]\n_ = sns.boxplot(data=data, x=\"visit_month\", y=\"updrs_sum\", ax=ax)\n_ = sns.pointplot(data=data, x=\"visit_month\", y=\"updrs_sum\", color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n_ = ax.set_title(\"UPDRS Sum of Scores by Month while OFF Medication\".format(x+1), fontsize=15)\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.set_ylabel(\"Score\")\n\ndata = train_clincial_data_copy[(train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] == \"On\")]\nax = axs[1]\n_ = sns.boxplot(data=data, x=\"visit_month\", y=\"updrs_sum\", ax=ax)\n_ = sns.pointplot(data=data, x=\"visit_month\", y=\"updrs_sum\", color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n_ = ax.set_title(\"UPDRS Sum of Scores by Month while ON Medication\".format(x+1), fontsize=15)\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.set_ylabel(\"Score\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With the sum of all UPDRS scores while OFF medication, we see an upwards trend as the visit month increases, which indicates that overall, disease progression is occurring. While ON medication, the trendline remains relatively flat until months > 96, which sees an increase in overall score. Again, this indicates that disease progression is occurring. If we combine both ON and OFF medication status:","metadata":{}},{"cell_type":"code","source":"train_clinical_data[\"updrs_sum\"] = train_clinical_data[\"updrs_1\"] + train_clinical_data[\"updrs_2\"] + train_clinical_data[\"updrs_3\"] + train_clinical_data[\"updrs_4\"]\ntrain_clincial_data_copy = train_clinical_data.copy()\ntrain_clincial_data_copy[\"upd23b_clinical_state_on_medication\"] = train_clincial_data_copy[\"upd23b_clinical_state_on_medication\"].fillna(\"Off\")\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n\nsns.set_style('darkgrid')\n\n_ = sns.boxplot(data=train_clincial_data_copy, x=\"visit_month\", y=\"updrs_sum\", ax=ax)\n_ = sns.pointplot(data=train_clincial_data_copy, x=\"visit_month\", y=\"updrs_sum\", color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n_ = ax.set_title(\"UPDRS Sum of Scores by Month\", fontsize=15)\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.set_ylabel(\"Score\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Overall, we see a trend of increasing UPDRS scores. This observation is important, as it suggests that our scores should likely see increases as time progresses, rather than decreases. This can be used as a post-processing check to ensure predictions being made by our machine learning algorithms make sense.","metadata":{}},{"cell_type":"markdown","source":"# 2.1.2 - Visit Month vs Protein Data\n\nWithout diving too much into the actual protein data, we should check to see if there are general trends regarding the breakdown of protein data by month.","metadata":{}},{"cell_type":"code","source":"train_protiens_copy = train_protiens.copy()\ntrain_protiens_copy[\"log_NPX\"] = np.log(train_protiens_copy[\"NPX\"])\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n\nsns.set_style('darkgrid')\n\n_ = sns.boxplot(data=train_protiens_copy, x=\"visit_month\", y=\"log_NPX\", ax=ax)\n_ = sns.pointplot(data=train_protiens_copy, x=\"visit_month\", y=\"log_NPX\", color=\"r\", ci=None, linestyles=[\":\"], ax=ax)\n_ = ax.set_title(\"NPX by Month\", fontsize=15)\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.set_ylabel(\"NPX\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unsurprisingly, we see stable amounts of protein expressions across each month category. There is a large amount of variance regarding the protein expression frequencies, but overall, we're seeing the same mean total NPX values repeated across the months. This likely means that there will be differences in the actual proteins expressed, rather than their absolute numbers. \n\nWe can check to see if there are any significant increases or decreases in `UniProt` proteins across the months. Looking at all 227 proteins is going to be challenging. For this, we'll look at proteins that have significant increases or decreases across the months. We'll examine protein counts for all 227 proteins, and then pick out ones that appear to have very large standard deviations compared to their mean. For this EDA, we'll look at any protein expression data that has a standard deviation of more than 25% of the mean value.","metadata":{}},{"cell_type":"code","source":"unique_proteins = train_protiens[\"UniProt\"].unique()\nunique_months = train_protiens[\"visit_month\"].unique()\n\nprotein_dict = dict()\nfor protein in unique_proteins:\n    if protein not in protein_dict:\n        protein_dict[protein] = {\n            \"months\": unique_months,\n            \"count_NPX\": [train_protiens[(train_protiens[\"UniProt\"] == protein) & (train_protiens[\"visit_month\"] == month)][\"NPX\"].count() for month in unique_months],\n            \"total_NPX\": [train_protiens[(train_protiens[\"UniProt\"] == protein) & (train_protiens[\"visit_month\"] == month)][\"NPX\"].sum() for month in unique_months],\n            \"avg_NPX\": [0 * len(unique_months)],\n        }\n        \nfor protein in unique_proteins:\n    protein_dict[protein][\"avg_NPX\"] = [float(total) / count for total, count in zip(protein_dict[protein][\"total_NPX\"], protein_dict[protein][\"count_NPX\"])]\n    \nfor protein in unique_proteins:\n    protein_dict[protein][\"min_NPX\"] = min(protein_dict[protein][\"avg_NPX\"])\n    protein_dict[protein][\"max_NPX\"] = max(protein_dict[protein][\"avg_NPX\"])\n    \nfor protein in unique_proteins:\n    protein_dict[protein][\"mean\"] = sum(protein_dict[protein][\"avg_NPX\"]) / len(protein_dict[protein][\"months\"])\n    protein_dict[protein][\"std\"] = sum([(total_NPX - protein_dict[protein][\"mean\"]) ** 2 for total_NPX in protein_dict[protein][\"avg_NPX\"]]) / (len(unique_months) - 1)\n    protein_dict[protein][\"std\"] = protein_dict[protein][\"std\"] ** 0.5\n    \nproteins_with_large_std = [protein for protein in unique_proteins if protein_dict[protein][\"std\"] > (protein_dict[protein][\"mean\"] * .25)]","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\n\nproteins_of_interest_by_month = {\n    \"UniProt\": [],\n    \"Visit Month\": [],\n    \"Average NPX\": [],\n}\nfor protein in proteins_with_large_std:\n    for month_index, month in enumerate(unique_months):\n        proteins_of_interest_by_month[\"UniProt\"].append(protein)\n        proteins_of_interest_by_month[\"Visit Month\"].append(month)\n        value = protein_dict[protein][\"avg_NPX\"][month_index]\n        value /= protein_dict[protein][\"max_NPX\"]\n        proteins_of_interest_by_month[\"Average NPX\"].append(value)\n        \ndf = pd.DataFrame(proteins_of_interest_by_month)\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 8))\n\nsns.set_style('darkgrid')\n\n_ = sns.lineplot(data=df, x=\"Visit Month\", y=\"Average NPX\", hue=\"UniProt\", style=\"UniProt\", ax=ax)\n_ = ax.set_title(\"Average NPX per Protein by Month\", fontsize=15)\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.set_ylabel(\"Average NPX\")\n_ = plt.legend(ncol=5)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some interesting observations to be made here. First, at months 30, 54, and 96 we see upward and downward spikes of the average levels of all the proteins of interest. Whether this is correlated with clinical data such as medication state or UPDRS scores is something we will look into in more detail below when we look directly at protein features. For now, we're just curious if there are correlations with proteins and visit month, which clearly there appear to be. \n\nThe second observation is that several proteins have both upward and downward movement. This means that the proteins may be positively or negatively correlated with UPDRS scores. \n\nThe third and final observation is that we are only looking at protein expression frequencies that have a very large variance from month to month (standard deviation > 25% of the mean). There may be other, subtler shifts in expression frequency that a machine learning algorithm can learn from.","metadata":{}},{"cell_type":"markdown","source":"# 2.2 - Protein UniProt and NPX\n\nWhile we've started to examine the impact of `visit_month` on various protein levels, we can also look at the protein expression levels themselves to see if there are correlations between them and UPDRS scores. There are a large number of proteins (227), so we'll first take a look overall before highlighting interesting correlations.","metadata":{}},{"cell_type":"code","source":"proteins = []\nprotein_dict = {}\nfor index, row in train_protiens.iterrows():\n    protein = row[\"UniProt\"]\n    if protein not in protein_dict:\n        protein_dict[protein] = {}\n        proteins.append(protein)\n    protein_dict[protein][row[\"visit_id\"]] = row[\"NPX\"]\n    \npeptides = []\npeptide_dict = {}\nfor index, row in train_peptides.iterrows():\n    peptide = row[\"Peptide\"]\n    if peptide not in peptide_dict:\n        peptide_dict[peptide] = {}\n        peptides.append(peptide)\n    peptide_dict[peptide][row[\"visit_id\"]] = row[\"PeptideAbundance\"]\n    \ntrain_copy = train_clinical_data.copy()\nfor protein in proteins:\n    train_copy[protein] = train_copy[\"visit_id\"].apply(lambda visit_id: 0 if visit_id not in protein_dict[protein] else protein_dict[protein][visit_id])\n    \nfor peptide in peptides:\n    train_copy[peptide] = train_copy[\"visit_id\"].apply(lambda visit_id: 0 if visit_id not in peptide_dict[peptide] else peptide_dict[peptide][visit_id])","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = []\nfeatures.extend(proteins)\n\n# Set missing values to null so our correlation matrix won't include 0 values in the correlation calculation\ntrain_copy[features] = train_copy[features].replace(0.0, np.nan)\n\nfeatures.extend([\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"])\n\ncorrelation_matrix = train_copy[features].corr(method=\"spearman\")\n\nfrom matplotlib.colors import SymLogNorm\n\nfig, axs = plt.subplots(nrows=8, ncols=1, figsize=(20, 40))\n\naxs = axs.flatten()\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,0:30],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[0], annot=True,\n)\n_ = axs[0].set_title(\"Spearman Correlation Matrix\", fontsize=15)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,30:60],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[1], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,60:90],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[2], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,90:120],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[3], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,120:150],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[4], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,150:180],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[5], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,180:210],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[6], annot=True,\n)\n\n_ = sns.heatmap(\n    correlation_matrix.iloc[-4:,210:227],\n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0, square=True, linewidths=.1, cbar=False, ax=axs[7], annot=True,\n)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a lot of proteins to examine with the correlation matrix. Let's start by defining what we would consider to be a somewhat significant correlation (positive or negative). Values that are 0.1 or below are likely to have little correlation to the UPDRS target scores, and are likely just noise. A quick scan reveals that there are several candidates that may not be useful in our regression:\n\n* `O00533`\n* `O14498`\n* `O15240`\n* `O15394`\n* `O43505`\n* `O60888`\n* `P00738`\n* `P01034`\n* `P01042`\n* `P01717`\n* `P02452`\n* `P02649`\n* `P02751`\n* `P02753`\n* `P02787`\n* `P04075`\n* `P04156`\n* `P04180`\n* `P04216`\n* `P05060`\n* `P05067`\n* `P05155`\n* `P05408`\n* `P05452`\n* `P06396`\n* `P07195`\n* `P07225`\n* `P07602`\n* `P07711`\n* `P07858`\n* `P08133`\n* `P08253`\n* `P08571`\n* `P09104`\n* `P09486`\n* `P09871`\n* `P10645`\n* `P11142`\n* `P13521`\n* `P13591`\n* `P13611`\n* `P13987`\n* `P14313`\n* `P14618`\n* `P17174`\n* `P19021`\n* `P23083`\n* `P23142`\n* `P39060`\n* `P40925`\n* `P43121`\n* `P49908`\n* `P54289`\n* `P55290`\n* `P61278`\n* `P61769`\n* `P61916`\n* `P98160`\n* `Q02818`\n* `Q06481`\n* `Q08380`\n* `Q12907`\n* `Q13332`\n* `Q14118`\n* `Q14508`\n* `Q14515`\n* `Q15904`\n* `Q16610`\n* `Q6UXB8`\n* `Q7Z3B1`\n* `Q8NBJ4`\n* `Q92520`\n* `Q92823`\n* `Q96KN2`\n* `Q99435`\n* `Q99674`\n* `Q9BY67`\n* `Q9NQ79`\n* `Q9NYU2`\n* `Q9UHG2`\n* `P01594`\n* `Q13449`\n* `Q99829`\n\nThere are some proteins that are weak correlates _only_ to `updrs_4`. These are:\n\n* `P00746`\n* `P02749`\n* `P02774`\n* `P04211`\n* `P04217`\n* `P05155`\n* `P06681`\n* `P19827`\n* `P20774`\n* `P31997`\n* `P61626`\n* `Q96BZ4`\n* `Q96PD5`\n\nThe challenge is going to be how we use this knowledge. Our correlation analysis only worked because we were able to ignore values that were missing. For machine learning regression to work, we'll need to satisfy one of the following conditions to use the data:\n\n* Have complete records for every protein type for every visit.\n* Figure out a way of imputing missing values.\n* Use a machine learning algorithm that implicitly handles missing data.\n\nLet's take a look at how our proteins appear across visits. Specifically, we know that there are are 2,615 unique visits. The question is how much of each protein we see given the total number of visits we have. If we only see a protein three or four times, even if it is correlated with an UPDRS score, it's likely not going to help out too much.","metadata":{}},{"cell_type":"code","source":"protein_counts = {}\n\nfor protein in proteins:\n    protein_counts[protein] = float(len(train_copy[(train_copy[protein] > 0.0)][protein])) / len(train_copy[protein]) * 100\n\nprotein_counts = dict(sorted(protein_counts.items(), key=lambda x:x[1], reverse=True))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 45))\n\n_ = sns.barplot(y=list(protein_counts.keys()), x=list(protein_counts.values()), ax=ax)\n_ = ax.set_title(\"% of Visits Containing Specified Protein\", fontsize=15)\n_ = ax.set_ylabel(\"Protein\")\n_ = ax.set_xlabel(\"% of Visits\")\n_ = ax.set_xlim([0, 100])","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It appears that for all of the protein data, proteins measurement data exists for at most 40% of the visits we have on record. This is going to be somewhat problematic to track trends. The instances where we don't have measurements for a specific protein are going to overwhelm examples where we do have protein measurements, creating a confounding effect. Even more problematic is the visit months where those measurements come from. ","metadata":{}},{"cell_type":"code","source":"protein_month_counts = {}\n\nfor protein in proteins:\n    protein_month_counts[protein] = {month: 0 for month in range(109)}\n    for x in range(109):\n        protein_month_counts[protein][x] = len(train_copy[(train_copy[protein] > 0.0) & (train_copy[\"visit_month\"] == x)][protein])","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n\n_ = sns.barplot(x=list(protein_month_counts[\"P00450\"].keys()), y=list(protein_month_counts[\"P00450\"].values()), ax=ax)\n_ = ax.set_title(\"Samples Available by Visit Month for Protein P00450\", fontsize=15)\n_ = ax.set_ylabel(\"# Samples\")\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.xaxis.set_major_locator(MultipleLocator(6))\n_ = ax.xaxis.set_major_formatter('{x:.0f}')\n_ = ax.xaxis.set_minor_locator(MultipleLocator(3))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should also look at it in terms of patients at each month. What percentage of patients are lacking protein data? Do we have representation of proteins at every month for at least some of our patients?","metadata":{}},{"cell_type":"code","source":"train_copy = train_copy.fillna(0)\ntrain_copy[\"missing_all\"] = train_copy[proteins].apply(lambda x: 1 if sum([y for y in x]) == 0 else 0, axis=1)\n\nmissing_month_counts = [train_copy[(train_copy[\"visit_month\"] == x)][\"missing_all\"].sum() / float(train_copy[(train_copy[\"visit_month\"] == x)][\"patient_id\"].count()) * 100 for x in range(109)]\nmissing_month_labels = [x for x in range(109)]\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20, 5))\n\n_ = sns.barplot(x=missing_month_labels, y=missing_month_counts, ax=ax)\n_ = ax.set_title(\"% of Patients Missing Protein Data by Visit Month\", fontsize=15)\n_ = ax.set_ylabel(\"% of Patients\")\n_ = ax.set_xlabel(\"Visit Month\")\n_ = ax.xaxis.set_major_locator(MultipleLocator(3))\n_ = ax.xaxis.set_major_formatter('{x:.0f}')\n_ = ax.xaxis.set_minor_locator(MultipleLocator(3))","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, at months 3, 9, 18, 30, 42, 54, and 96, we are lacking protein data for nearly all of the patients in the study.","metadata":{}},{"cell_type":"markdown","source":"# 3 - Research Papers\n\nThere is a body of real-world research that may provide some targeted insights into the data that we have at hand.\n\n# 3.1 - Cerebrospinal Fluid Peptides as Potential Parkinson Disease Biomarkers (2015)\n\nThe research by Shi et al (2015) looks specifically at CSF proteins and peptides that are potential indicators of Parkinson's Disease. Of those identified, the following are available in the training data that we have available:\n\n* Proteins:\n    * `P00450` - Ceruloplasmin (CP)\n    * `P07333` - Macrophage colony-stimulating factor 1 receptor (CSF1R)\n    * `P10451` - Osteopontin (SPP1)\n    * `P01033` - Metalloproteinase inhibitor 1 (TIMP1)\n    * `P01008` - Antithrombin-III (SERPINC1)\n    * `P02647` - Apolipoprotein A-I (APOA1)\n    * `P01024` - Complement C3 (C3)\n    * `Q92876` - Kallikrein-6 (KLK6)\n* Peptides:\n    * `GAYPLSIEPIGVR` - associated with protein Ceruloplasmin (CP)\n    * `EPGLC(UniMod_4)TWQSLR` - associated with protein Metalloproteinase inhibitor 1 (TIMP1)\n    * `WQEEMELYR` - associated with protein Apolipoprotein A-I (APOA1)\n    * `QPSSAFAAFVK` - associated with protein Complement C3 (C3)\n    * `GLVSWGNIPC(UniMod_4)GSK` - associated with protein Kallikrein-6 (KLK6)\n    \nWe should check to see how these protein levels impact UPDRS scores. Let's start by checking correlation of these peptide and protein levels against various UPDRS scores.","metadata":{}},{"cell_type":"code","source":"proteins = [\"P00450\", \"P07333\", \"P10451\", \"P01033\", \"P01008\", \"P02647\", \"P01024\", \"Q92876\"]\npeptides = [\"GAYPLSIEPIGVR\", \"EPGLC(UniMod_4)TWQSLR\", \"WQEEMELYR\", \"QPSSAFAAFVK\", \"GLVSWGNIPC(UniMod_4)GSK\"]\n\nprotein_dict = {}\nfor index, row in train_protiens.iterrows():\n    protein = row[\"UniProt\"]\n    if protein not in protein_dict:\n        protein_dict[protein] = {}\n    protein_dict[protein][row[\"visit_id\"]] = row[\"NPX\"]\n    \npeptide_dict = {}\nfor index, row in train_peptides.iterrows():\n    peptide = row[\"Peptide\"]\n    if peptide not in peptide_dict:\n        peptide_dict[peptide] = {}\n    peptide_dict[peptide][row[\"visit_id\"]] = row[\"PeptideAbundance\"]\n    \ntrain_copy = train_clinical_data.copy()\nfor protein in proteins:\n    train_copy[protein] = train_copy[\"visit_id\"].apply(lambda visit_id: 0 if visit_id not in protein_dict[protein] else protein_dict[protein][visit_id])\n    \nfor peptide in peptides:\n    train_copy[peptide] = train_copy[\"visit_id\"].apply(lambda visit_id: 0 if visit_id not in peptide_dict[peptide] else peptide_dict[peptide][visit_id])\n    \nfeatures = []\nfeatures.extend(proteins)\nfeatures.extend(peptides)\n\n# Set missing values to null so our correlation matrix won't include 0 values in the correlation calculation\ntrain_copy[features] = train_copy[features].replace(0.0, np.nan)\n\nfeatures.extend([\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"])\n\ncorrelation_matrix = train_copy[features].corr(method=\"spearman\")\n\nfrom matplotlib.colors import SymLogNorm\n\nf, ax = plt.subplots(figsize=(20, 20))\n_ = sns.heatmap(\n    correlation_matrix.iloc[13:17,0:13], \n    cmap=sns.diverging_palette(230, 20, as_cmap=True), \n    center=0,\n    square=True, \n    linewidths=.1, \n    cbar=False,\n    ax=ax,\n    annot=True,\n)\n_ = ax.set_title(\"Spearman Correlation Matrix for Peptides and Protiens of Interest vs UPDRS scores\", fontsize=15)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some interesting observations here. None of the peptides or proteins have any significant positive or negative correlation to UPDRS scores except for:\n\n* Protein `P07333` has a weak negative correlation to `updrs_3`\n* Peptide `GLVSWGNIPC(UniMod_4)GSK` has a weak negative correlation to `updrs_1`. \n\nThese observations fall in line with the findings from the paper. In brief, the authors noted that no single protein or peptide in isolation had a clear correlation to UPDRS scores - it was only in combination with other peptides and proteins that a stronger signal was present. The paper outlines a 2-peptide model that had strong correlations with overall disease severity. Unfortunately, the training dataset does not have the correct combination of proteins and peptides as described in the paper. Nonetheless, these two findings above may be enough to provide minimal lift.","metadata":{}},{"cell_type":"markdown","source":"# 4 - Models\n\nGiven what we know of the data, we can now create a series of models and see if our knowledge of features and their properties can be used to our advantage.\n\n# 4.1 - Baseline CatBoost Model\n\nThe first model we'll construct is a simple one - we'll use absolutely no protein or peptide data. In essence, we'll end up just using prior information about visit month to make predictions for the future. Function for computing SMAPE score was graciously borrowed from [@carlmcbrideellis](https://www.kaggle.com/carlmcbrideellis) post on [How to calculate the SMAPE score](https://www.kaggle.com/competitions/tabular-playground-series-jan-2022/discussion/298201).","metadata":{}},{"cell_type":"code","source":"train_dict = {}\n\nfor index, row in train_clinical_data.iterrows():\n    patient_id = row[\"patient_id\"]\n    visit_month = row[\"visit_month\"]\n    if patient_id not in train_dict:\n        train_dict[patient_id] = {}\n    train_dict[patient_id][visit_month] = {\n           \"updrs_1\": row[\"updrs_1\"],\n           \"updrs_2\": row[\"updrs_2\"],\n           \"updrs_3\": row[\"updrs_3\"],\n           \"updrs_4\": row[\"updrs_4\"],\n    }\n    \ntrain = train_clinical_data.copy()\ntrain[\"month_offset\"] = 0\n\nfor index, row in train_clinical_data.iterrows():\n    visit_id = row[\"visit_id\"]\n    patient_id = row[\"patient_id\"]\n    visit_month = row[\"visit_month\"]\n    month_offsets = [6, 12, 24]\n    for month_offset in month_offsets:\n        new_visit_month = visit_month + month_offset\n        if new_visit_month in train_dict[patient_id]:\n            new_row = {\n                \"visit_id\": visit_id,\n                \"visit_month\": visit_month,\n                \"month_offset\": month_offset,\n                \"patient_id\": patient_id,\n                \"updrs_1\": train_dict[patient_id][new_visit_month][\"updrs_1\"],\n                \"updrs_2\": train_dict[patient_id][new_visit_month][\"updrs_2\"],\n                \"updrs_3\": train_dict[patient_id][new_visit_month][\"updrs_3\"],\n                \"updrs_4\": train_dict[patient_id][new_visit_month][\"updrs_4\"],\n                \"upd23b_clinical_state_on_medication\": row[\"upd23b_clinical_state_on_medication\"],\n            }\n            train = train.append(new_row, ignore_index=True)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nfrom sklearn.model_selection import KFold\n\ndef smape(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) / 200.0\n    diff = np.abs(y_true - y_pred) / denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)\n\nfeatures = [\n    'visit_month', 'month_offset',\n]\n\ntrain_copy = train.copy()\ntrain_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nn_folds = 5\nskf = KFold(n_splits=n_folds, random_state=2023, shuffle=True)\ntrain_oof_preds = np.zeros((train.shape[0], 4))\nsmape_scores = []\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train_copy, train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train_copy.iloc[train_index]), pd.DataFrame(train_copy.iloc[test_index])\n    y_train, y_valid = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[train_index], train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = CatBoostRegressor(\n        eval_metric=\"MultiRMSE\",\n        loss_function=\"MultiRMSE\",\n        random_state=2023,\n        num_boost_round=5000,\n        od_type=\"Iter\",\n        od_wait=200,\n        use_best_model=True,\n        verbose=0,    \n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        verbose=0,\n        early_stopping_rounds=200,\n        use_best_model=True,\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    train_oof_preds[test_index] = np.rint(oof_preds)\n\n    reshaped_truth = y_valid.to_numpy().reshape(-1, 1)\n    new_preds = np.rint(oof_preds)\n    reshaped_preds = new_preds.reshape(-1, 1)\n\n    local_smape = smape(reshaped_truth.flatten(), reshaped_preds.flatten())\n    smape_scores.append(local_smape)\n    print(\": SMAPE = {}\".format(local_smape))\n    \nsmape_baseline = np.mean(smape_scores)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": SMAPE = {}\".format(smape_baseline))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n\ndata = pd.DataFrame({\"Fold\": [x + 1 for x in range(n_folds)], \"SMAPE\": smape_scores})\n_ = sns.lineplot(x=\"Fold\", y=\"SMAPE\", data=data, ax=ax)\n_ = ax.set_title(\"SMAPE per Fold\", fontsize=15)\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_xlabel(\"Fold #\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, we get a SMAPE score of 95.7, which isn't great. There are however improvements we can make to this score.","metadata":{}},{"cell_type":"markdown","source":"# 4.2 - Constant UPDRS 4\n\nOverall, our model currently cannot learn enough information about UPDRS 4 due to missing and null values. A simple way to handle this is to zero it out. This isn't very good from a clinical standpoint, but it will likely generate lift for us, since we won't get penalized for the many times we're likely to predict a value where there should be none. For example, see discussion [here](https://www.kaggle.com/competitions/amp-parkinsons-disease-progression-prediction/discussion/393104).","metadata":{}},{"cell_type":"code","source":"features = [\n    'visit_month', 'month_offset',\n]\n\ntrain_copy = train.copy()\ntrain_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nn_folds = 5\nskf = KFold(n_splits=n_folds, random_state=2023, shuffle=True)\ntrain_oof_preds = np.zeros((train.shape[0], 4))\nsmape_scores = []\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train_copy, train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train_copy.iloc[train_index]), pd.DataFrame(train_copy.iloc[test_index])\n    y_train, y_valid = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[train_index], train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = CatBoostRegressor(\n        eval_metric=\"MultiRMSE\",\n        loss_function=\"MultiRMSE\",\n        random_state=2023,\n        num_boost_round=5000,\n        od_type=\"Iter\",\n        od_wait=200,\n        use_best_model=True,\n        verbose=0,    \n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        verbose=0,\n        early_stopping_rounds=200,\n        use_best_model=True,\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    oof_preds[:, 3] = 0\n    train_oof_preds[test_index] = np.rint(oof_preds)\n\n    reshaped_truth = y_valid.to_numpy().reshape(-1, 1)\n    new_preds = np.rint(oof_preds)\n    reshaped_preds = new_preds.reshape(-1, 1)\n\n    local_smape = smape(reshaped_truth.flatten(), reshaped_preds.flatten())\n    smape_scores.append(local_smape)\n    print(\": SMAPE = {}\".format(local_smape))\n    \nsmape_updrs40 = np.mean(smape_scores)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": SMAPE = {}\".format(smape_updrs40))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n\ndata = pd.DataFrame({\"Fold\": [x + 1 for x in range(n_folds)], \"SMAPE\": smape_scores})\n_ = sns.lineplot(x=\"Fold\", y=\"SMAPE\", data=data, ax=ax)\n_ = ax.set_title(\"SMAPE per Fold\", fontsize=15)\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_xlabel(\"Fold #\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, simply setting the UPDRS 4 value to 0 improves our SMAPE score. There is obviously room here to make improvements, especially if we could leverage information to make better UPDRS 4 predictions. For models moving forward, we'll continue to use the zeroed out UPDRS score.","metadata":{}},{"cell_type":"markdown","source":"# 4.3 - Supplemental Data\n\nIf we are going to continue to ignore protein and peptide data, then we can add in the additional clinical data to the mix. This is likely to generate lift for us, since we give the regressor more information to work with.","metadata":{"tags":[]}},{"cell_type":"code","source":"supplemental_dict = {}\n\nfor index, row in supplemental_clinical_data.iterrows():\n    patient_id = row[\"patient_id\"]\n    visit_month = row[\"visit_month\"]\n    if patient_id not in supplemental_dict:\n        supplemental_dict[patient_id] = {}\n    supplemental_dict[patient_id][visit_month] = {\n           \"updrs_1\": row[\"updrs_1\"],\n           \"updrs_2\": row[\"updrs_2\"],\n           \"updrs_3\": row[\"updrs_3\"],\n           \"updrs_4\": row[\"updrs_4\"],\n    }\n    \nadditional = supplemental_clinical_data.copy()\nadditional[\"month_offset\"] = 0\n\nfor index, row in supplemental_clinical_data.iterrows():\n    visit_id = row[\"visit_id\"]\n    patient_id = row[\"patient_id\"]\n    visit_month = row[\"visit_month\"]\n    month_offsets = [6, 12, 24]\n    for month_offset in month_offsets:\n        new_visit_month = visit_month + month_offset\n        if new_visit_month in supplemental_dict[patient_id]:\n            new_row = {\n                \"visit_id\": visit_id,\n                \"visit_month\": visit_month,\n                \"month_offset\": month_offset,\n                \"patient_id\": patient_id,\n                \"updrs_1\": supplemental_dict[patient_id][new_visit_month][\"updrs_1\"],\n                \"updrs_2\": supplemental_dict[patient_id][new_visit_month][\"updrs_2\"],\n                \"updrs_3\": supplemental_dict[patient_id][new_visit_month][\"updrs_3\"],\n                \"updrs_4\": supplemental_dict[patient_id][new_visit_month][\"updrs_4\"],\n                \"upd23b_clinical_state_on_medication\": row[\"upd23b_clinical_state_on_medication\"],\n            }\n            additional = additional.append(new_row, ignore_index=True)\n\nadditional[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = additional[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nfeatures = [\n    'visit_month', 'month_offset',\n]\n\ntrain_copy = train.copy()\ntrain_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nn_folds = 5\nskf = KFold(n_splits=n_folds, random_state=2023, shuffle=True)\ntrain_oof_preds = np.zeros((train.shape[0], 4))\nsmape_scores = []\n\nchunk_size = int(len(additional) / n_folds)\nadditional_chunks = [additional[i:i+chunk_size] for i in range(0, len(additional), chunk_size)]\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train_copy, train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train_copy.iloc[train_index]), pd.DataFrame(train_copy.iloc[test_index])\n    y_train, y_valid = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[train_index], train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_train_features = pd.concat([x_train_features, additional_chunks[fold]]).reset_index(drop=True)\n    y_train = y_train.append(additional_chunks[fold][[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]])\n    \n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = CatBoostRegressor(\n        eval_metric=\"MultiRMSE\",\n        loss_function=\"MultiRMSE\",\n        random_state=2023,\n        num_boost_round=5000,\n        od_type=\"Iter\",\n        od_wait=200,\n        use_best_model=True,\n        verbose=0,    \n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        verbose=0,\n        early_stopping_rounds=200,\n        use_best_model=True,\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    oof_preds[:, 3] = 0\n    train_oof_preds[test_index] = np.rint(oof_preds)\n\n    reshaped_truth = y_valid.to_numpy().reshape(-1, 1)\n    new_preds = np.rint(oof_preds)\n    reshaped_preds = new_preds.reshape(-1, 1)\n\n    local_smape = smape(reshaped_truth.flatten(), reshaped_preds.flatten())\n    smape_scores.append(local_smape)\n    print(\": SMAPE = {}\".format(local_smape))\n    \nsmape_additional = np.mean(smape_scores)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": SMAPE = {}\".format(smape_additional))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n\ndata = pd.DataFrame({\"Fold\": [x + 1 for x in range(n_folds)], \"SMAPE\": smape_scores})\n_ = sns.lineplot(x=\"Fold\", y=\"SMAPE\", data=data, ax=ax)\n_ = ax.set_title(\"SMAPE per Fold\", fontsize=15)\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_xlabel(\"Fold #\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see a little improvement over using the clinical data alone. This is likely going to help us in instances where the hidden test data contains no protein information.","metadata":{}},{"cell_type":"markdown","source":"# 4.4 - Medication State\n\nWhile the medication state of a patient isn't available on our test data, there may still be some interest in it, as we saw that the medication state did have a direct impact on UPDRS scores over time. Let's take a look and see if it could potentially provide lift if we had it.","metadata":{}},{"cell_type":"code","source":"features = [\n    'visit_month', 'month_offset', 'med_state',\n]\n\ntrain_copy = train.copy()\ntrain_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nn_folds = 5\nskf = KFold(n_splits=n_folds, random_state=2023, shuffle=True)\ntrain_oof_preds = np.zeros((train.shape[0], 4))\nsmape_scores = []\n\ntrain_copy[\"med_state\"] = train_copy[\"upd23b_clinical_state_on_medication\"]\ntrain_copy[\"med_state\"] = train_copy[\"med_state\"].apply(lambda x: 0 if x == \"Off\" else 1 if x == \"On\" else 2)\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train_copy, train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train_copy.iloc[train_index]), pd.DataFrame(train_copy.iloc[test_index])\n    y_train, y_valid = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[train_index], train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = CatBoostRegressor(\n        eval_metric=\"MultiRMSE\",\n        loss_function=\"MultiRMSE\",\n        random_state=2023,\n        num_boost_round=5000,\n        od_type=\"Iter\",\n        od_wait=200,\n        use_best_model=True,\n        verbose=0,    \n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        verbose=0,\n        early_stopping_rounds=200,\n        use_best_model=True,\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    oof_preds[:, 3] = 0\n    train_oof_preds[test_index] = np.rint(oof_preds)\n\n    reshaped_truth = y_valid.to_numpy().reshape(-1, 1)\n    new_preds = np.rint(oof_preds)\n    reshaped_preds = new_preds.reshape(-1, 1)\n\n    local_smape = smape(reshaped_truth.flatten(), reshaped_preds.flatten())\n    smape_scores.append(local_smape)\n    print(\": SMAPE = {}\".format(local_smape))\n    \nsmape_med = np.mean(smape_scores)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": SMAPE = {}\".format(smape_med))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n\ndata = pd.DataFrame({\"Fold\": [x + 1 for x in range(n_folds)], \"SMAPE\": smape_scores})\n_ = sns.lineplot(x=\"Fold\", y=\"SMAPE\", data=data, ax=ax)\n_ = ax.set_title(\"SMAPE per Fold\", fontsize=15)\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_xlabel(\"Fold #\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there is lift to our model if we take into account medication state. This suggests that maybe a classifier capable of soft-labeling medication state may be applicable, assuming there is signal in the protein data to provide context for the classifier to work with.","metadata":{}},{"cell_type":"markdown","source":"# 4.5 - Protein Data\n\nUp until now, we haven't looked at all at protein or peptide information. Let's see what happens when we add in raw numbers.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupKFold\n\nfeatures = [\n    \"visit_month\", \"month_offset\", \"O00391\", \"O00533\", \"O00584\", \"O14498\", \"O14773\", \"O14791\", \"O15240\", \n    \"O15394\", \"O43505\", \"O60888\", \"O75144\", \"O75326\", \"O94919\", \"P00441\", \"P00450\", \"P00734\", \"P00736\", \n    \"P00738\", \"P00746\", \"P00747\", \"P00748\", \"P00751\", \"P01008\", \"P01009\", \"P01011\", \"P01019\", \"P01023\", \n    \"P01024\", \"P01031\", \"P01033\", \"P01034\", \"P01042\", \"P01344\", \"P01591\", \"P01608\", \"P01621\", \"P01717\", \n    \"P01780\", \"P01833\", \"P01834\", \"P01857\", \"P01859\", \"P01860\", \"P01861\", \"P01876\", \"P01877\", \"P02452\", \n    \"P02647\", \"P02649\", \"P02652\", \"P02655\", \"P02656\", \"P02671\", \"P02675\", \"P02679\", \"P02747\", \"P02748\",\n    \"P02749\", \"P02750\", \"P02751\", \"P02753\", \"P02760\", \"P02763\", \"P02765\", \"P02766\", \"P02768\", \"P02774\",\n    \"P02787\", \"P02790\", \"P04004\", \"P04075\", \"P04156\", \"P04180\", \"P04196\", \"P04207\", \"P04211\", \"P04216\", \n    \"P04217\", \"P04275\", \"P04406\", \"P04433\", \"P05060\", \"P05067\", \"P05090\", \"P05155\", \"P05156\", \"P05408\", \n    \"P05452\", \"P05546\", \"P06310\", \"P06396\", \"P06454\", \"P06681\", \"P06727\", \"P07195\", \"P07225\", \"P07333\", \n    \"P07339\", \"P07602\", \"P07711\", \"P07858\", \"P07998\", \"P08123\", \"P08133\", \"P08253\", \"P08294\", \"P08493\", \n    \"P08571\", \"P08603\", \"P08637\", \"P08697\", \"P09104\", \"P09486\", \"P09871\", \"P10451\", \"P10643\", \"P10645\", \n    \"P10909\", \"P11142\", \"P11277\", \"P12109\", \"P13473\", \"P13521\", \"P13591\", \"P13611\", \"P13671\", \"P13987\", \n    \"P14174\", \"P14314\", \"P14618\", \"P16035\", \"P16070\", \"P16152\", \"P16870\", \"P17174\", \"P17936\", \"P18065\", \n    \"P19021\", \"P19652\", \"P19823\", \"P19827\", \"P20774\", \"P20933\", \"P23083\", \"P23142\", \"P24592\", \"P25311\", \n    \"P27169\", \"P30086\", \"P31997\", \"P35542\", \"P36222\", \"P36955\", \"P36980\", \"P39060\", \"P40925\", \"P41222\", \n    \"P43121\", \"P43251\", \"P43652\", \"P49588\", \"P49908\", \"P51884\", \"P54289\", \"P55290\", \"P61278\", \"P61626\", \n    \"P61769\", \"P61916\", \"P80748\", \"P98160\", \"Q02818\", \"Q06481\", \"Q08380\", \"Q12805\", \"Q12841\", \"Q12907\", \n    \"Q13283\", \"Q13332\", \"Q13451\", \"Q13740\", \"Q14118\", \"Q14508\", \"Q14515\", \"Q14624\", \"Q15904\", \"Q16270\",\n    \"Q16610\", \"Q562R1\", \"Q6UX71\", \"Q6UXB8\", \"Q6UXD5\", \"Q7Z3B1\", \"Q7Z5P9\", \"Q8IWV7\", \"Q8N2S1\", \"Q8NBJ4\",\n    \"Q8NE71\", \"Q92520\", \"Q92823\", \"Q92876\", \"Q96BZ4\", \"Q96KN2\", \"Q96PD5\", \"Q96S96\", \"Q99435\", \"Q99674\", \n    \"Q99832\", \"Q99969\", \"Q9BY67\", \"Q9HDC9\", \"Q9NQ79\", \"Q9NYU2\", \"Q9UBR2\", \"Q9UBX5\", \"Q9UHG2\", \"Q9UNU6\", \n    \"Q9Y646\", \"Q9Y6R7\", \"P01594\", \"P02792\", \"P32754\", \"P60174\", \"Q13449\", \"Q99683\", \"Q99829\", \"Q9UKV8\"\n]\n\ntrain_copy = train.copy()\ntrain_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]] = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].fillna(0)\n\nproteins = train_protiens[\"UniProt\"].unique()\n\nprotein_visit_dict = {}\nfor protein in proteins:\n    if protein not in protein_visit_dict:\n        protein_visit_dict[protein] = {}\n    for index, row in train_protiens[(train_protiens[\"UniProt\"] == protein)].iterrows():\n        visit_id = row[\"visit_id\"]\n        protein_visit_dict[protein][visit_id] = row[\"NPX\"]\n        \nfor protein in proteins:\n    train_copy[protein] = train_copy[\"visit_id\"].apply(\n           lambda visit_id: protein_visit_dict[protein][visit_id] if visit_id in protein_visit_dict[protein] else 0\n    )\n\nn_folds = 5\nskf = GroupKFold(n_splits=n_folds)\ntrain_oof_preds = np.zeros((train.shape[0], 4))\nsmape_scores = []\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train_copy, train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]], groups=train_copy[\"patient_id\"])):\n    print(\"-------> Fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train_copy.iloc[train_index]), pd.DataFrame(train_copy.iloc[test_index])\n    y_train, y_valid = train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[train_index], train_copy[[\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    model = CatBoostRegressor(\n        eval_metric=\"MultiRMSE\",\n        loss_function=\"MultiRMSE\",\n        random_state=2023,\n        num_boost_round=5000,\n        od_type=\"Iter\",\n        od_wait=200,\n        use_best_model=True,\n        verbose=0,    \n    )\n    model.fit(\n        x_train_features[features], \n        y_train,\n        eval_set=[(x_valid_features[features], y_valid)],\n        verbose=0,\n        early_stopping_rounds=200,\n        use_best_model=True,\n    )\n    oof_preds = model.predict(x_valid_features[features])\n    oof_preds[:, 3] = 0\n    train_oof_preds[test_index] = np.rint(oof_preds)\n\n    reshaped_truth = y_valid.to_numpy().reshape(-1, 1)\n    new_preds = np.rint(oof_preds)\n    reshaped_preds = new_preds.reshape(-1, 1)\n\n    local_smape = smape(reshaped_truth.flatten(), reshaped_preds.flatten())\n    smape_scores.append(local_smape)\n    print(\": SMAPE = {}\".format(local_smape))\n    \nsmape_protein = np.mean(smape_scores)\nprint(\"--> Overall results for out of fold predictions\")\nprint(\": SMAPE = {}\".format(smape_protein))\n\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n\ndata = pd.DataFrame({\"Fold\": [x + 1 for x in range(n_folds)], \"SMAPE\": smape_scores})\n_ = sns.lineplot(x=\"Fold\", y=\"SMAPE\", data=data, ax=ax)\n_ = ax.set_title(\"SMAPE per Fold\", fontsize=15)\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_xlabel(\"Fold #\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.x - Model Comparisons\n\nWe can compare the performance of each of our models to see which one performs the best. The red dashed line indicates baseline performance that we are looking to beat.","metadata":{}},{"cell_type":"code","source":"bar, ax = plt.subplots(figsize=(20, 10))\nax = sns.barplot(\n    x=[\"Baseline\", \"Constant UPDRS 4\", \"Supplemental Data\", \"Medication State\", \"Protein Data\"],\n    y=[\n        smape_baseline,\n        smape_updrs40,\n        smape_additional,\n        smape_med,\n        smape_protein,\n    ]\n)\n_ = ax.axhline(y=69.51, color='r', linestyle='--')\n_ = ax.set_title(\"SMAPE Score (Lower is Better)\", fontsize=15)\n_ = ax.set_xlabel(\"\")\n_ = ax.set_ylabel(\"SMAPE\")\n_ = ax.set_ylim([61, 97])\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(x=p.get_x()+(p.get_width()/2), y=height, s=\"{:.4f}\".format(height), ha=\"center\")","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 - Conclusions\n\nThere are several conclusions based on our observations:\n\n* The size of the dataset means that memory pressure will likely not be too great. \n* There are a total of 248 patients in the clinical data, and 771 patients in the supplemental data.\n* In terms of missing information:\n    * There are no null entries in the protein or peptide data.\n    * There are null entries in the clinical data and supplemental data.\n        * We cannot assume that null values indicate a 0 value for features such as UPDRS assessment parts, as values of 0 indicate a \"normal\" response.\n        * Null values in the medication state of the patient cannot be assumed to be either `On` or `Off`.\n* Duplicated data appears very infrequently, and is unlikely to impact machine learning models if not explicitly filtered out.\n* Clinical data appears to have a greater range in `visit_month` when compared to supplemental data (0 - 108 months compared to 0 - 36 months).\n    * In general, clinical and supplementary data is very different in terms of data distributions, as confirmed statistically, and through adversarial validation.\n* In reference to research by Shi et al (2015):\n    * The protein and peptide samples obtained do not not occur in the combinations needed to act as clear indicators as disease progression or severity.\n    * Our correlation analysis suggested that protein `P07333` has a weak negative correlation to `updrs_3`, and peptide `GLVSWGNIPC(UniMod_4)GSK` has a weak negative correlation to `updrs_1`.","metadata":{}},{"cell_type":"markdown","source":"# References\n\n* Goetz, C. G., Tilley, B. C., Shaftman, S. R., Stebbins, G. T., Fahn, S., Martinez-Martin, P., Poewe, W., Sampaio, C., Stern, M. B., Dodel, R., Dubois, B., Holloway, R., Jankovic, J., Kulisevsky, J., Lang, A. E., Lees, A., Leurgans, S., LeWitt, P. A., Nyenhuis, D., Olanow, C. W., Rascol, O., Schrag, A., Teresi, J. A., van Hilten, J. J., and LaPelle, N. (2008). Movement Disorder Society-Sponsored Revision of the Unified Parkinson’s Disease Rating Scale (MDS-UPDRS): Scale Presentation and Clinimetric Testing Results. _Movement Disorders_, 23(15), 2129–2170. DOI: [10.1002/mds.22340](https://doi.org/10.1002/mds.22340)\n* Holden, S.K., Finseth, T., Sillau, S.H. and Berman, B.D. (2018). Progression of MDS-UPDRS Scores Over Five Years in De Novo Parkinson Disease from the Parkinson's Progression Markers Initiative Cohort. _Movement Disorders Clinical Practice_, 5, 47-53. DOI: [10.1002/mdc3.12553](https://doi.org/10.1002/mdc3.12553)\n* Shi, M., Movius, J., Dator, R. P., Aro, P., Zhao, Y., Pan, C., Lin, X., Bammler, T. K., Stewart, T., Zabetian, C. P., Peskind, E. R., Hu, S. F., Quinn, J. F., Galasko, D., & Zhang, J. (2015). Cerebrospinal Fluid Peptides as Potential Parkinson Disease Biomarkers: A Staged Pipeline for Discovery and Validation*. _Molecular & Cellular Proteomics_, 14(3), 544–555. DOI: [10.1074/mcp.m114.040576](https://doi.org/10.1074/mcp.m114.040576)","metadata":{}}]}