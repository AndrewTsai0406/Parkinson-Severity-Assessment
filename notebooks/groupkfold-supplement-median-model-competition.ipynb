{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt \nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\n\nfrom sklearn.svm import SVR  \nfrom sklearn.linear_model import *\nfrom sklearn.metrics import make_scorer\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import KFold,GridSearchCV,RandomizedSearchCV,GroupKFold\nfrom sklearn.preprocessing import OrdinalEncoder,Normalizer,MinMaxScaler,StandardScaler","metadata":{"execution":{"iopub.status.busy":"2023-04-10T06:59:21.993921Z","iopub.execute_input":"2023-04-10T06:59:21.994832Z","iopub.status.idle":"2023-04-10T06:59:22.002610Z","shell.execute_reply.started":"2023-04-10T06:59:21.994758Z","shell.execute_reply":"2023-04-10T06:59:22.001523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def smape(y_true, y_pred):\n    y_true += 1\n    y_pred += 1\n    \n    numerator = np.abs(y_true - y_pred)\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n    positive_index = (y_true!=0) | (y_pred!=0)\n    smape = np.zeros(len(y_true))\n    smape[positive_index] = numerator[positive_index] / denominator[positive_index]\n    smape = 100 * np.mean(smape)\n    return smape","metadata":{"execution":{"iopub.status.busy":"2023-04-10T06:59:22.004439Z","iopub.execute_input":"2023-04-10T06:59:22.005297Z","iopub.status.idle":"2023-04-10T06:59:22.020561Z","shell.execute_reply.started":"2023-04-10T06:59:22.005254Z","shell.execute_reply":"2023-04-10T06:59:22.019113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_proteins=pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_proteins.csv\")\n# train_peptides=pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_peptides.csv')\n# train_clinical=pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv')\n\n# def features(df, train_proteins, train_peptides):\n#     proteins_npx_ft = train_proteins\\\n#         .groupby('visit_id')\\\n#         .agg(NPX_min=('NPX','min'), NPX_max=('NPX','max'), NPX_mean=('NPX','mean'), NPX_std=('NPX','std'))\\\n#         .reset_index()\n#     peptides_PeptideAbundance_ft = train_peptides\\\n#         .groupby('visit_id')\\\n#         .agg(Abe_min=('PeptideAbundance','min'), Abe_max=('PeptideAbundance','max'),Abe_mean=('PeptideAbundance','mean'), Abe_std=('PeptideAbundance','std'))\\\n#         .reset_index()\n#     df = pd.merge(df, proteins_npx_ft, on = 'visit_id', how = 'left')\n#     df = pd.merge(df, peptides_PeptideAbundance_ft, on = 'visit_id', how = 'left')\n#     return df\n\n# train_df = features(train_clinical, train_proteins, train_peptides)\n# sds = StandardScaler()\n# scale_col = ['visit_month','NPX_min','NPX_max','NPX_mean','NPX_std', 'Abe_min', 'Abe_max', 'Abe_mean', 'Abe_std']\n# train_df[scale_col] = sds.fit_transform(train_df[scale_col])\n\n# train_df","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:51:37.288568Z","iopub.execute_input":"2023-04-10T07:51:37.289071Z","iopub.status.idle":"2023-04-10T07:51:38.212752Z","shell.execute_reply.started":"2023-04-10T07:51:37.289028Z","shell.execute_reply":"2023-04-10T07:51:38.211475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import warnings\n# warnings.filterwarnings(\"ignore\")\n# models = {}\n\n# target = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\n# fold = 17\n# # num_folds = {u:[] for u in target}\n# # for fold in range(2,27,5):\n# #     print('<'*50,f'n_fold:{fold}','>'*50)\n\n# model_pool = [Lars(),RandomForestRegressor(),SVR(),Lasso(),LGBMRegressor(),XGBRegressor()]\n# for u in target:\n#     # Drop NAs\n#     temp = train_df.dropna(subset=[u]+scale_col) \n    \n#     # For updrs_3, dropping 0's improve results\n#     if u == 'updrs_3':\n#         temp = temp[temp[u] != 0]\n\n#     # Train data\n#     X = temp[scale_col].values\n#     y = temp[u] \n\n#     enc = OrdinalEncoder()\n#     groups = enc.fit_transform(pd.DataFrame(temp.patient_id)).reshape(1,-1)[0].tolist()\n#     cv = GroupKFold(n_splits=fold)\n\n#     model_candidates = []\n#     scores = []\n#     for ind, model in enumerate(model_pool):\n#         model_candidates.append(\n#             RandomizedSearchCV(model,\n#                                {item[0]:[item[1]] for item in model.get_params().items()},\n#                                cv = cv.split(X, y, groups),\n#                                scoring=make_scorer(smape),\n#                                verbose = -1\n#                               ).fit(X,y)\n#         )\n#         scores.append((ind,model_candidates[-1].best_score_))\n#         print(u,str(model_candidates[ind].estimator).split('(')[0],model_candidates[-1].best_score_)\n\n#     winning_model = model_candidates[sorted(scores,key = lambda x:x[1])[0][0]]\n#     num_folds[u].append(winning_model.best_score_)\n#     print(f\"Pick best performing model for {u}:{str(winning_model.estimator).split('(')[0]}\",'\\n','-'*50)\n#     models[u] = winning_model\n    \n# # for lst in num_folds.values():\n# #     plt.plot(lst)\n# # plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:51:39.917263Z","iopub.execute_input":"2023-04-10T07:51:39.917693Z","iopub.status.idle":"2023-04-10T07:53:46.106166Z","shell.execute_reply.started":"2023-04-10T07:51:39.917657Z","shell.execute_reply":"2023-04-10T07:53:46.104836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\nsup = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv')\ntrain = train.append(sup, ignore_index=True).drop(['upd23b_clinical_state_on_medication'],axis=1)\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-04-10T06:59:22.022272Z","iopub.execute_input":"2023-04-10T06:59:22.023042Z","iopub.status.idle":"2023-04-10T06:59:22.062390Z","shell.execute_reply.started":"2023-04-10T06:59:22.023002Z","shell.execute_reply":"2023-04-10T06:59:22.061278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nmodels = {}\n\ntarget = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\nfold = 17\n# num_folds = {u:[] for u in target}\n# for fold in range(2,27,5):\n#     print('<'*50,f'n_fold:{fold}','>'*50)\n\nmodel_pool = [Lars(),RandomForestRegressor(),SVR(),Lasso(),LGBMRegressor(),XGBRegressor()]\nfor u in target:\n    # Drop NAs\n    temp = train.dropna(subset=[u]) \n\n    # For updrs_3, dropping 0's improve results\n    if u == 'updrs_3':\n        temp = temp[temp[u] != 0]\n\n    # Train data\n    X = temp['visit_month'].values.reshape(-1,1)\n    y = temp[u] \n\n    enc = OrdinalEncoder()\n    groups = enc.fit_transform(pd.DataFrame(temp.patient_id)).reshape(1,-1)[0].tolist()\n    cv = GroupKFold(n_splits=fold)\n\n    model_candidates = []\n    scores = []\n    for ind, model in enumerate(model_pool):\n        model_candidates.append(\n            RandomizedSearchCV(model,\n                               {item[0]:[item[1]] for item in model.get_params().items()},\n                               cv = cv.split(X, y, groups),\n                               scoring=make_scorer(smape),\n                               verbose = -1\n                              ).fit(X,y)\n        )\n        scores.append((ind,model_candidates[-1].best_score_))\n        print(u,str(model_candidates[ind].estimator).split('(')[0],model_candidates[-1].best_score_)\n\n    winning_model = model_candidates[sorted(scores,key = lambda x:x[1])[0][0]]\n    print(f\"Pick best performing model for {u}:{str(winning_model.estimator).split('(')[0]}\",'\\n','-'*50)\n    models[u] = winning_model\n    \n    \n#     num_folds[u].append(winning_model.best_score_)\n    \n# for lst in num_folds.values():\n#     plt.plot(lst)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:24:36.400512Z","iopub.execute_input":"2023-04-10T07:24:36.400956Z","iopub.status.idle":"2023-04-10T07:26:41.819957Z","shell.execute_reply.started":"2023-04-10T07:24:36.400914Z","shell.execute_reply":"2023-04-10T07:26:41.818479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_X_y_train_dataset(df, updrs_part, plus_month):\n# #     df_ = df.dropna(subset=[f'updrs_{updrs_part}'])\n#     df_ = df\n#     X_visit_ids = []\n#     y_visit_ids = []\n#     patient_ids = df['patient_id'].unique()\n#     for i, patient_id in enumerate(patient_ids):\n#         patient_df = df_[df_['patient_id']==patient_id]\n#         plus_months = patient_df['visit_month'] + plus_month\n#         plus_months = patient_df.query('visit_month in @plus_months')['visit_month']\n#         original_months = plus_months - plus_month\n        \n#         X_visit_id = [f'{patient_id}_{original_month}' for original_month in original_months]\n#         y_visit_id = [f'{patient_id}_{plus_month}' for plus_month in plus_months]\n        \n#         X_visit_ids.extend(X_visit_id)\n#         y_visit_ids.extend(y_visit_id)\n    \n#     X = df_.query('visit_id in @X_visit_ids')\n#     X = X.drop(['patient_id', 'updrs_1', 'updrs_2', 'updrs_3', 'updrs_4'], axis=1)\n#     X.reset_index(drop=True, inplace=True)\n    \n#     y = df_.query('visit_id in @y_visit_ids')\n#     y = y[['visit_id', f'updrs_{updrs_part}']]\n#     y.reset_index(drop=True, inplace=True)\n#     return X, y\n\n# def create_X_y_dict(df):\n#     X_dict = {}\n#     y_dict = {}\n#     for updrs_part in [1, 2, 3, 4]:\n#         for plus_month in [0, 6, 12, 24]:\n#             X, y = create_X_y_train_dataset(df, updrs_part, plus_month)\n#             key = f'updrs_{updrs_part}_plus_month{plus_month}'\n            \n#             df_ = pd.DataFrame({'patient_id':[visit_id.split('_')[0] for visit_id in X.visit_id]})\n#             X = X.join(df_)\n            \n#             X = X[y[f'updrs_{updrs_part}'].notna()]\n#             y = y[y[f'updrs_{updrs_part}'].notna()]\n            \n#             # For updrs_3, dropping 0's improve results\n#             if updrs_part == 3:\n#                 X = X[y['updrs_3'] != 0]\n#                 y = y[y['updrs_3'] != 0]\n            \n#             X_dict[key] = X\n#             y_dict[key] = y\n#     return X_dict, y_dict\n\n# X_dict, y_dict = create_X_y_dict(train)\n\n# for updrs in [1, 2, 3, 4]:\n#     for plus_month in [0, 6, 12, 24]:\n#         key = f'updrs_{updrs}_plus_month{plus_month}'\n#         print(f'{key} => {len(X_dict[key])}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.093597Z","iopub.execute_input":"2023-04-10T07:00:37.094009Z","iopub.status.idle":"2023-04-10T07:00:37.102485Z","shell.execute_reply.started":"2023-04-10T07:00:37.093968Z","shell.execute_reply":"2023-04-10T07:00:37.101079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# discard target na\nupdrs_1_plus_month0 => 4624:4624\nupdrs_1_plus_month6 => 2664:2664\nupdrs_1_plus_month12 => 2640:2640\nupdrs_1_plus_month24 => 1889:1889\nupdrs_2_plus_month0 => 4622:4622\nupdrs_2_plus_month6 => 2662:2662\nupdrs_2_plus_month12 => 2639:2639\nupdrs_2_plus_month24 => 1888:1888\nupdrs_3_plus_month0 => 4442:4442\nupdrs_3_plus_month6 => 2547:2547\nupdrs_3_plus_month12 => 2384:2384\nupdrs_3_plus_month24 => 1681:1681\nupdrs_4_plus_month0 => 2872:2872\nupdrs_4_plus_month6 => 1827:1827\nupdrs_4_plus_month12 => 1905:1905\nupdrs_4_plus_month24 => 1440:1440\n------------------------------------\n# discard all na\nupdrs_1_plus_month0 => 4624:4624\nupdrs_1_plus_month6 => 2663:2663\nupdrs_1_plus_month12 => 2640:2640\nupdrs_1_plus_month24 => 1889:1889\nupdrs_2_plus_month0 => 4622:4622\nupdrs_2_plus_month6 => 2661:2661\nupdrs_2_plus_month12 => 2639:2639\nupdrs_2_plus_month24 => 1888:1888\nupdrs_3_plus_month0 => 4442:4442\nupdrs_3_plus_month6 => 2533:2533\nupdrs_3_plus_month12 => 2373:2373\nupdrs_3_plus_month24 => 1669:1669\nupdrs_4_plus_month0 => 2872:2872\nupdrs_4_plus_month6 => 1482:1482\nupdrs_4_plus_month12 => 1390:1390\nupdrs_4_plus_month24 => 880:880","metadata":{}},{"cell_type":"code","source":"# from sklearn.linear_model import *\n# import warnings\n# warnings.filterwarnings(\"ignore\")\n\n# models = {}\n\n# linear_params = [{\n#     'alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 1]\n#     }]\n# target = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\n\n# # num_folds = {u:[] for u in target}\n# # for fold in range(2,21):\n# best_scores = {}\n# for u in target:\n\n#     # Drop NAs\n#     temp = train.dropna(subset=[u]) \n\n#     # For updrs_3, dropping 0's improve results\n#     if u == 'updrs_3':\n#         temp = temp[temp[u] != 0]\n\n#     # Train data\n#     X = temp['visit_month'].values.reshape(-1,1)\n#     y = temp[u] \n\n#     enc = OrdinalEncoder()\n#     groups = enc.fit_transform(pd.DataFrame(temp.patient_id)).reshape(1,-1)[0].tolist()\n#     cv = GroupKFold(n_splits=10)\n    \n#     m1 = RandomizedSearchCV(Lasso(),{item[0]:[item[1]] for item in Lasso().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m2 = RandomizedSearchCV(ElasticNet(),{item[0]:[item[1]] for item in ElasticNet().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m3 = RandomizedSearchCV(ElasticNetCV(),{item[0]:[item[1]] for item in ElasticNetCV().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m4 = RandomizedSearchCV(Lars(),{item[0]:[item[1]] for item in Lars().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m5 = RandomizedSearchCV(LarsCV(),{item[0]:[item[1]] for item in LarsCV().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m6 = RandomizedSearchCV(Lasso(),{item[0]:[item[1]] for item in Lasso().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m7 = RandomizedSearchCV(LassoCV(),{item[0]:[item[1]] for item in LassoCV().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m8 = RandomizedSearchCV(LassoLars(),{item[0]:[item[1]] for item in LassoLars().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m9 = RandomizedSearchCV(LassoLarsIC(),{item[0]:[item[1]] for item in LassoLarsIC().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m10 = RandomizedSearchCV(OrthogonalMatchingPursuit(),{item[0]:[item[1]] for item in OrthogonalMatchingPursuit().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m11 = RandomizedSearchCV(LinearRegression(),{item[0]:[item[1]] for item in LinearRegression().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m12 = RandomizedSearchCV(Ridge(),{item[0]:[item[1]] for item in Ridge().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n#     m13 = RandomizedSearchCV(RidgeCV(),{item[0]:[item[1]] for item in RidgeCV().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n# #         m = RandomizedSearchCV(OrthogonalMatchingPursuitCV(),{item[0]:[item[1]] for item in OrthogonalMatchingPursuitCV().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n# #         m = RandomizedSearchCV(SGDRegressor(),{item[0]:[item[1]] for item in SGDRegressor().get_params().items()},cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n    \n#     best_scores[u] = sorted([(f'm{i}',globals()[f'm{i}'].best_score_) for i in range(1,14)],key = lambda x:x[1])\n# best_scores","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.106076Z","iopub.execute_input":"2023-04-10T07:00:37.106614Z","iopub.status.idle":"2023-04-10T07:00:37.122539Z","shell.execute_reply.started":"2023-04-10T07:00:37.106568Z","shell.execute_reply":"2023-04-10T07:00:37.120973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# models = {}\n# linear_params = [{\n#     'alpha':[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 1]\n#     }]\n\n# # num_folds = {f'updrs_{updrs}_plus_month{plus_month}': [] for updrs in [1, 2, 3 ,4] for plus_month in [0, 6, 12, 24]}\n# # for fold in range(2,21):\n# for updrs in [1, 2, 3 ,4]:\n#     for plus_month in [0, 6, 12, 24]:\n#         key = f'updrs_{updrs}_plus_month{plus_month}'\n#         print(key)\n#         X = X_dict[key]['visit_month'].values.reshape(-1,1)\n#         y = y_dict[key][f'updrs_{updrs}']\n\n#         enc = OrdinalEncoder()\n#         groups = enc.fit_transform(pd.DataFrame(X_dict[key].patient_id)).reshape(1,-1)[0].tolist()\n#         cv = GroupKFold(n_splits=10)\n#         ls = RandomizedSearchCV(Lasso(),linear_params,cv = cv.split(X, y, groups),scoring=make_scorer(smape),verbose = -1).fit(X,y)\n\n#         num_folds[key].append(ls.best_score_)\n#         print('linear best param',ls.best_params_)\n#         print('linear best score',ls.best_score_)\n#         models['ls_' + key] = ls","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.124286Z","iopub.execute_input":"2023-04-10T07:00:37.125162Z","iopub.status.idle":"2023-04-10T07:00:37.141418Z","shell.execute_reply.started":"2023-04-10T07:00:37.125084Z","shell.execute_reply":"2023-04-10T07:00:37.140202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_clinical_data = pd.read_csv(\"/kaggle/input/amp-parkinsons-disease-progression-prediction/train_clinical_data.csv\")\ndf_supplemental_clinical_data = pd.read_csv('/kaggle/input/amp-parkinsons-disease-progression-prediction/supplemental_clinical_data.csv')\n\ntarget_columns_clinical_data = ['updrs_1',]\ntarget_columns_clinical_and_supplemental_data = ['updrs_2','updrs_3', 'updrs_4']\n\ntarget_visit_month_medians_clinical_data = df_train_clinical_data.groupby('visit_month')[target_columns_clinical_data].median()\ntarget_visit_month_medians_clinical_and_supplemental_data = pd.concat((df_train_clinical_data,df_supplemental_clinical_data),\n                                                                      axis=0).groupby('visit_month')[target_columns_clinical_and_supplemental_data].median()\n\n# target_visit_month_medians_clinical_data = df_train_clinical_data.groupby('visit_month')[target_columns_clinical_data].mean()\n# target_visit_month_medians_clinical_and_supplemental_data = pd.concat((df_train_clinical_data,df_supplemental_clinical_data),\n#                                                                       axis=0).groupby('visit_month')[target_columns_clinical_and_supplemental_data].mean()\n\n# target_visit_month_medians_clinical_data = df_train_clinical_data.groupby('visit_month')[target_columns_clinical_data].apply(pd.DataFrame.mode).groupby('visit_month').mean()\n# target_visit_month_medians_clinical_and_supplemental_data = pd.concat((df_train_clinical_data,df_supplemental_clinical_data),\n#                                                                       axis=0).groupby('visit_month')[target_columns_clinical_and_supplemental_data].apply(pd.DataFrame.mode).groupby('visit_month').mean()\n\n\n# Drop 5th month visit that is coming from the supplemental clinical data\ntarget_visit_month_medians_clinical_and_supplemental_data = target_visit_month_medians_clinical_and_supplemental_data.drop(5)\n\n# Concatenate visit_month medians of targets\ntarget_visit_month_medians = pd.concat(\n    (target_visit_month_medians_clinical_data,target_visit_month_medians_clinical_and_supplemental_data),\n    axis=1, ignore_index=False)\n\n# Replace expanding window max of updrs values with current updrs values\ntarget_visit_month_medians = target_visit_month_medians.expanding(min_periods=1).max()\ntarget_visit_month_medians","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.145872Z","iopub.execute_input":"2023-04-10T07:00:37.146725Z","iopub.status.idle":"2023-04-10T07:00:37.202701Z","shell.execute_reply.started":"2023-04-10T07:00:37.146658Z","shell.execute_reply":"2023-04-10T07:00:37.201449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n\n    smape = 100 / len(y_true) * np.sum(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n\n    return smape\n\n\ndef score(df, target_columns, prediction_columns):\n    \n    y_true = []\n    y_pred = []\n    \n    for target_column, prediction_column in zip(target_columns, prediction_columns):\n        target_idx = df[target_column].notna()\n        y_true.append(df.loc[target_idx, target_column].values + 1)\n        y_pred.append(df.loc[target_idx, prediction_column].values + 1)\n        \n    y_true = np.concatenate(y_true)\n    y_pred = np.concatenate(y_pred)\n        \n    score = symmetric_mean_absolute_percentage_error(\n        y_true=y_true,\n        y_pred=y_pred\n    )\n    \n    return score\n\nfold_columns = ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']\ntarget_columns = ['updrs_1', 'updrs_2', 'updrs_3', 'updrs_4']\n\nfor target_column in target_columns:\n        \n    target_idx = df_train_clinical_data[target_column].notna()\n    df_train = df_train_clinical_data.loc[target_idx]\n    print(f'Target: {target_column} Dataset Shape: {df_train.shape}')\n        \n    df_train_clinical_data.loc[target_idx, f'{target_column}_predictions'] = df_train_clinical_data.loc[target_idx, 'visit_month'].map(target_visit_month_medians[target_column])\n    val_score = score(\n        df=df_train_clinical_data.loc[target_idx],\n        target_columns=[target_column],\n        prediction_columns=[f'{target_column}_predictions']\n    )\n    print(f'Validation SMAPE: {val_score:.4f}\\n')\n    \nglobal_oof_score = score(\n    df=df_train_clinical_data,\n    target_columns=target_columns,\n    prediction_columns=[f'{target_column}_predictions' for target_column in target_columns]\n)\nprint(f'Global OOF SMAPE: {global_oof_score:.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.204487Z","iopub.execute_input":"2023-04-10T07:00:37.205221Z","iopub.status.idle":"2023-04-10T07:00:37.245055Z","shell.execute_reply.started":"2023-04-10T07:00:37.205175Z","shell.execute_reply":"2023-04-10T07:00:37.243967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import amp_pd_peptide\n# amp_pd_peptide.make_env.func_dict['__called__'] = False\n# env = amp_pd_peptide.make_env()   \n# iter_test = env.iter_test()\n\n# counter = 0\n# model_picks = [0,0,0,0]\n# for (test, test_peptides, test_proteins, sample_submission) in iter_test:\n#     df = test[['visit_id']].drop_duplicates('visit_id')\n    \n#     for visit_id in df.visit_id:\n#         X = test.query(f'visit_id==\"{visit_id}\"')[:1].visit_month.values.reshape(-1,1)\n#         for updrs_part in [1,2,3,4]:\n#             for plus_month in [0, 6, 12, 24]:\n#                 key = f'updrs_{updrs_part}_plus_month{plus_month}'\n#                 rating = models[f'ls_{key}'].predict(X)\n#                 prediction_id = f\"{visit_id}_updrs_{updrs_part}_plus_{plus_month}_months\"\n#                 index = sample_submission.query(f'prediction_id==\"{prediction_id}\"').index\n#                 sample_submission.loc[index, 'rating'] = rating\n        \n        \n#     sample_submission['patient_id'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[0].astype(int)\n#     sample_submission['current_visit_month'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[1].astype(int)\n#     sample_submission['visit_month_offset'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[5].astype(int)\n#     sample_submission['prediction_visit_month'] = sample_submission['current_visit_month'] + sample_submission['visit_month_offset'].astype(int)\n#     sample_submission['updrs'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[3].astype(int)\n\n#     for updrs in range(1, 5):\n#         if model_picks[updrs_part-1]:\n#             updrs_idx = sample_submission['updrs'] == updrs\n#             sample_submission.loc[updrs_idx, 'rating'] = sample_submission.loc[updrs_idx, 'prediction_visit_month'].map(target_visit_month_medians[f'updrs_{updrs}'])\n#             missing_idx = sample_submission['rating'].isnull()\n#             for idx, row in sample_submission[updrs_idx & missing_idx].iterrows():\n#                 target_visit_month_median_idx = np.argmin(np.abs(target_visit_month_medians.index - row['prediction_visit_month']))\n#                 sample_submission.loc[idx, 'rating'] = target_visit_month_medians.iloc[target_visit_month_median_idx, updrs - 1]\n    \n#     sample_submission = sample_submission.loc[:, ['prediction_id', 'rating']]\n    \n#     if counter == 0:\n#             display(test)\n#             display(sample_submission)\n#     counter += 1\n#     env.predict(sample_submission)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.246734Z","iopub.execute_input":"2023-04-10T07:00:37.247434Z","iopub.status.idle":"2023-04-10T07:00:37.253937Z","shell.execute_reply.started":"2023-04-10T07:00:37.247390Z","shell.execute_reply":"2023-04-10T07:00:37.252867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import amp_pd_peptide\namp_pd_peptide.make_env.func_dict['__called__'] = False\nenv = amp_pd_peptide.make_env()   \niter_test = env.iter_test()\n\ntarget = [\"updrs_1\", \"updrs_2\", \"updrs_3\", \"updrs_4\"]\n\ncounter = 0\nmodel_picks = [0,1,0,1]\nfor (test, test_peptides, test_proteins, sample_submission) in iter_test:\n    df = test[['visit_id']].drop_duplicates('visit_id')\n    \n    for visit_id in df.visit_id:\n        X = test.query(f'visit_id==\"{visit_id}\"')[:1].visit_month.values.reshape(-1,1)\n        for u in target:\n            for plus_month in [0, 6, 12, 24]:\n                \n                rating = models[u].predict([[X[0][0]+plus_month]])\n                \n                prediction_id = f\"{visit_id}_{u}_plus_{plus_month}_months\"\n                index = sample_submission.query(f'prediction_id==\"{prediction_id}\"').index\n                sample_submission.loc[index, 'rating'] = rating\n        \n        \n    sample_submission['patient_id'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[0].astype(int)\n    sample_submission['current_visit_month'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[1].astype(int)\n    sample_submission['visit_month_offset'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[5].astype(int)\n    sample_submission['prediction_visit_month'] = sample_submission['current_visit_month'] + sample_submission['visit_month_offset'].astype(int)\n    sample_submission['updrs'] = sample_submission.apply('prediction_id').str.split('_', expand=True)[3].astype(int)\n\n    for updrs in range(1, 5):\n        if model_picks[updrs-1]:\n            updrs_idx = sample_submission['updrs'] == updrs\n            sample_submission.loc[updrs_idx, 'rating'] = sample_submission.loc[updrs_idx, 'prediction_visit_month'].map(target_visit_month_medians[f'updrs_{updrs}'])\n            missing_idx = sample_submission['rating'].isnull()\n            for idx, row in sample_submission[updrs_idx & missing_idx].iterrows():\n                target_visit_month_median_idx = np.argmin(np.abs(target_visit_month_medians.index - row['prediction_visit_month']))\n                sample_submission.loc[idx, 'rating'] = target_visit_month_medians.iloc[target_visit_month_median_idx, updrs - 1]\n    \n    sample_submission = sample_submission.loc[:, ['prediction_id', 'rating']]\n    \n    if counter == 0:\n            display(test)\n            display(sample_submission)\n    counter += 1\n    env.predict(sample_submission)","metadata":{"execution":{"iopub.status.busy":"2023-04-10T07:00:37.256868Z","iopub.execute_input":"2023-04-10T07:00:37.257274Z","iopub.status.idle":"2023-04-10T07:00:37.707675Z","shell.execute_reply.started":"2023-04-10T07:00:37.257233Z","shell.execute_reply":"2023-04-10T07:00:37.706239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}